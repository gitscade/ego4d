{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325a1267",
   "metadata": {},
   "source": [
    "# Evaluate Plots V2\n",
    "\n",
    "test pair에 대한 iteration을 수행한다.\n",
    "\n",
    "1. pickle을 통해서 모든 아이템을 다 읽는다.\n",
    "2. 현재 source sequence를 읽는다.\n",
    "3. scene similarity를 읽는다.\n",
    "- mistral로 계산한 inclusion ratio\n",
    "- 직접 계산한 entity similarity\n",
    "\n",
    "4. action sequence similarity를 계산한다.\n",
    "- agent4 필터 통과와 상관없이 플롯\n",
    "- agent4 필터를 통과하면 플롯\n",
    "\n",
    "5. activity taxnomy similarity를 계산한다.\n",
    "- agent4 필터 통과와 상관없이 플롯\n",
    "- agent4 필터를 통과하면 플롯\n",
    "\n",
    "\n",
    "다음의 pandas colum을 구성한다. (568x13 정도 되나?)\n",
    "\n",
    "없는 곳은 None표시를 한다.\n",
    "\n",
    "source idx, target idx, \n",
    "augmentation_id, inclusion_ratio, entity_similarity\n",
    "goal_category, goal_description\n",
    "core activity_gt, core activity_inf\n",
    "sequence sim, taxonomy sim\n",
    "sequence bool, taxonomy bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38f736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/project/data/ego4d_annotation/goalstep/\n",
      "all: goalstep vids: 717\n",
      "all: spatial vids: 211\n",
      "dbinit: testuid excluded: goalstep vids: 646\n",
      "dbinit: testuid excluded: spatial vids: 140\n",
      "dbinit: testuid list: test goalstep vids: 71\n",
      "dbinit: testuid list: test spatial vids: 71\n",
      "dbinit: MAKE_DOCU: goalstep_document_list: 38613\n",
      "dbinit: MAKE_DOCU: goalstep_document_list: 1366\n",
      "dbinit: MAKE_DOCU: spatial_document_list: 1243\n",
      "dbinit: MAKE_DOCUAKE: spatial_document_list: 752\n",
      "LOAD FAISS GOALSTEP: /root/project/data/ego4d_annotation/goalstep_docarray_faiss\n",
      "LOAD FAISS SPATIAL: /root/project/data/ego4d_annotation/spatial_docarray_faiss\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "from sklearn.manifold import TSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score\n",
    "\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
    "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
    "from util import util_constants\n",
    "from util import util_funcs\n",
    "import f4_evaluate.evaluate_scene as evaluate_scene\n",
    "import f1_init.database_init as database_init\n",
    "import f1_init.agent_init as agent_init\n",
    "import f1_init.constants_init as constants_init\n",
    "\n",
    "#Computing similarity\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "#PATHS\n",
    "PATH_CURR_FOLDER = os.path.abspath('') \n",
    "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
    "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
    "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
    "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
    "\n",
    "#PAIRSIM DATA\n",
    "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
    "\n",
    "#AUGMENTED DATA PATH\n",
    "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
    "TEST_SPATIAL_ANNOTATION_V2_PATH = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_v2/'\n",
    "\n",
    "#BASELINE RESULT PATHS\n",
    "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag/'))\n",
    "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag/'))\n",
    "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1direct/'))\n",
    "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1goalmediation/'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    try:          \n",
    "         with open(path, \"rb\") as f:\n",
    "             data = pickle.load(f)\n",
    "             return data\n",
    "    except:\n",
    "         return None\n",
    "    \n",
    "def check_file(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            pickle.load(f)  # try loading to ensure file is not empty or corrupted\n",
    "        return True\n",
    "    except (EOFError, FileNotFoundError, PermissionError, IsADirectoryError, pickle.UnpicklingError):\n",
    "        return False\n",
    "    \n",
    "#=====================================\n",
    "# SIMILARITIES v1 SINGLE STRING SBERT MODEL\n",
    "#=====================================\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "def safe_parse_sequence(seq):\n",
    "    if seq is None:\n",
    "        return []\n",
    "    if isinstance(seq, list):\n",
    "        return seq\n",
    "    try:\n",
    "        return ast.literal_eval(seq)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(\"taxonomy safe parse value error\")\n",
    "        return []\n",
    "\n",
    "def safe_parse_taxonomy(tax):\n",
    "    if tax is None:\n",
    "        return {}\n",
    "    if isinstance(tax, dict):\n",
    "        return tax\n",
    "    try:\n",
    "        return json.loads(tax)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return {}\n",
    "\n",
    "def compute_similarities(entry, embed_model):\n",
    "    # --- Parse sequences ---\n",
    "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
    "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
    "\n",
    "    if not source_seq or not target_seq:\n",
    "        seq_similarity = 0.0\n",
    "    else:\n",
    "        source_seq_str = ' '.join(source_seq)\n",
    "        target_seq_str = ' '.join(target_seq)\n",
    "        source_seq_emb = embed_model.encode(source_seq_str)\n",
    "        target_seq_emb = embed_model.encode(target_seq_str)\n",
    "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
    "\n",
    "    # --- Parse taxonomies ---\n",
    "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
    "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
    "\n",
    "    if not source_tax or not target_tax:\n",
    "        tax_similarity = 0.0\n",
    "    else:\n",
    "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
    "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
    "        source_tax_emb = embed_model.encode(source_tax_str)\n",
    "        target_tax_emb = embed_model.encode(target_tax_str)\n",
    "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
    "\n",
    "    return seq_similarity, tax_similarity\n",
    "\n",
    "#=====================================\n",
    "# SIMILARITIES v2 WEIGHTED LINEAR TAXONOMY SEMANTICS MODEL\n",
    "# weight by level\n",
    "# Compare only values\n",
    "#=====================================\n",
    "def compute_weighted_tax_similarity(entry, embed_model):\n",
    "    '''\n",
    "    func: calculate weighted taxonomy for values only\n",
    "    w = [0.5,0.2,0.1,0.1,0.1]\n",
    "    empty/impossible for both: w0=0.5\n",
    "    empty/impossible for target: w0=0\n",
    "    '''\n",
    "    tax_sim =[]\n",
    "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
    "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
    "\n",
    "    # set weight & main\n",
    "    is_main = True\n",
    "    weights = [0.5, 0.3, 0.1, 0.1, 0.1]\n",
    "\n",
    "    if not source_tax or not target_tax:\n",
    "        tax_similarity = 0.0\n",
    "    else:\n",
    "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
    "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
    "        source_tax_emb = embed_model.encode(source_tax_str)\n",
    "        target_tax_emb = embed_model.encode(target_tax_str)\n",
    "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
    "\n",
    "        source_items = list(source_tax.items())\n",
    "        target_items = list(target_tax.items())\n",
    "        for i in range(5):\n",
    "            weight = weights[i]\n",
    "            source_tax[i].values\n",
    "        # source longer\n",
    "\n",
    "        # both same\n",
    "\n",
    "        # target longer\n",
    "\n",
    "\n",
    "    return tax_sim\n",
    "\n",
    "def compute_weighted_seq_similarity():\n",
    "    seq_sim =[]\n",
    "    # overall sim\n",
    "    \n",
    "    # set weight & main\n",
    "    is_main = True\n",
    "    weights = [0.5, 0.3, 0.1, 0.1, 0.1]\n",
    "    \n",
    "\n",
    "    # source longer\n",
    "\n",
    "    # both same\n",
    "\n",
    "    # target longer\n",
    "\n",
    "    return seq_sim\n",
    "\n",
    "#=====================================\n",
    "# SIMILARITIES v3 WEIGHTED SIMILARITY & GED MODEL\n",
    "# COMPLETELY DIFFERENT WEIGHT FOR insertion, deletion of nodes\n",
    "# \n",
    "#=====================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12e164",
   "metadata": {},
   "source": [
    "## Read Results\n",
    "\n",
    "read a list of 568 pickle sets in 8 elements for 8 levels in augmentation\n",
    "\n",
    "\n",
    "\n",
    "make dictionary\n",
    "-fill every information\n",
    "-fill every calculatable information\n",
    "-save as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf074b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "1\n",
      "[{'idx': 475, 'agent': 'agent3'}]\n",
      "0\n",
      "[]\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
    "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
    "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def check_missing_index(baseline_result_path:str, baseline:str):\n",
    "    '''\n",
    "    func: return list of missing index for earlier agent set.\n",
    "    output: dict_list of {idx:int, agent:\"agent_name\"} that if missing\n",
    "    '''\n",
    "    dict_list =[]\n",
    "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    length = 71 * len(augmodes) #8levels, 8files    \n",
    "\n",
    "    # daseline different loadout \n",
    "    for i in range(length):\n",
    "        prefix = f\"pair{i}_\" \n",
    "        path_source = baseline_result_path +\"/\"+ prefix + \"sourceinfo.pkl\"\n",
    "        path_target = baseline_result_path +\"/\"+ prefix + \"targetinfo.pkl\"\n",
    "        path_agent1a = baseline_result_path +\"/\"+ prefix + \"agent1a.pkl\"\n",
    "        path_agent1b = baseline_result_path +\"/\"+ prefix + \"agent1b.pkl\"\n",
    "        path_agent2a = baseline_result_path +\"/\"+ prefix + \"agent2a.pkl\"\n",
    "        path_agent2b = baseline_result_path +\"/\"+ prefix + \"agent2b.pkl\"\n",
    "        path_agent3 = baseline_result_path +\"/\"+ prefix + \"agent3.pkl\"\n",
    "        path_agent4 = baseline_result_path +\"/\"+ prefix + \"agent4.pkl\"        \n",
    "        if baseline == \"1direct\":\n",
    "            if not check_file(path_source):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"sourceinfo\"})\n",
    "                continue\n",
    "            if not check_file(path_target):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"targetinfo\"})\n",
    "                continue         \n",
    "            if not check_file(path_agent3):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent3\"})\n",
    "                continue                \n",
    "            # if not check_file(path_agent4):\n",
    "            #     dict_list.append({\"idx\": i, \"agent\": \"agent4\"})\n",
    "            #     continue                \n",
    "           \n",
    "        if baseline == \"1goalmediation\":\n",
    "            if not check_file(path_source):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"sourceinfo\"})\n",
    "                continue\n",
    "            if not check_file(path_target):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"targetinfo\"})\n",
    "                continue\n",
    "            if not check_file(path_agent1a):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent1a\"})\n",
    "                continue               \n",
    "            if not check_file(path_agent3):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent3\"})\n",
    "                continue               \n",
    "            if not check_file(path_agent4):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent4\"})\n",
    "                continue                  \n",
    "\n",
    "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
    "            if not check_file(path_source):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"sourceinfo\"})\n",
    "                continue\n",
    "            if not check_file(path_target):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"targetinfo\"})\n",
    "                continue\n",
    "            if not check_file(path_agent1a):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent1a\"})\n",
    "                continue       \n",
    "            if not check_file(path_agent1b):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent1b\"})\n",
    "                continue             \n",
    "            if not check_file(path_agent2a):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent2a\"})\n",
    "                continue          \n",
    "            if not check_file(path_agent2b):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent2b\"})\n",
    "                continue        \n",
    "            if not check_file(path_agent3):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent3\"})\n",
    "                continue                                    \n",
    "            if not check_file(path_agent4):\n",
    "                dict_list.append({\"idx\": i, \"agent\": \"agent4\"})\n",
    "                continue               \n",
    "\n",
    "    return dict_list                                  \n",
    "\n",
    "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
    "    '''\n",
    "    func: make single baseline list\n",
    "    '''\n",
    "    baseline_result_path = baseline_result_path + \"/\"\n",
    "    baseline_results = []\n",
    "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    length = 71 * 8 #8levels, 8files\n",
    "\n",
    "    for i in range(length):\n",
    "    # for i in range(568):\n",
    "        # print(i)\n",
    "        dict = {\n",
    "            \"idx\":None,\"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"target_uid\": None, \"baseline\": None, \"augmode\": None, \n",
    "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
    "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
    "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
    "            }\n",
    "\n",
    "        prefix = f\"pair{i}_\"\n",
    "        augmode = i%len(augmodes)\n",
    "        # FILL RAW DATA\n",
    "        # print(i)\n",
    "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
    "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
    "        dict[\"idx\"] = i\n",
    "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
    "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
    "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
    "        dict[\"target_uid\"] = targetinfo_dict['target_uid']\n",
    "        dict[\"baseline\"] = baseline\n",
    "        dict[\"augmode\"] = augmode\n",
    "\n",
    "\n",
    "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
    "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
    "\n",
    "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
    "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
    "\n",
    "        \n",
    "        # based on baselines     \n",
    "        if baseline == \"1direct\":\n",
    "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
    "        if baseline == \"1goalmediation\":\n",
    "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
    "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
    "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
    "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
    "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
    "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
    "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
    "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
    "\n",
    "\n",
    "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
    "        if(booleans == None):\n",
    "            ## No values whatsover\n",
    "            dict[\"sequence_boolean\"] = False\n",
    "            dict[\"taxonomy_boolean\"] = False \n",
    "        else:\n",
    "            values = [\n",
    "                line.split(\":\")[1].strip()\n",
    "                for line in booleans.strip().splitlines()\n",
    "                if \":\" in line\n",
    "            ]\n",
    "            # print(values)\n",
    "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
    "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
    "            # print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
    "        \n",
    "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
    "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
    "        # SBERT for block level semantics\n",
    "\n",
    "        if dict['target_sequence'] != None:\n",
    "            \n",
    "            # Preprocess sequece to make sequence a single string\n",
    "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
    "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
    "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
    "            \n",
    "            # print(dict['source_taxonomy'])\n",
    "            # print(dict['target_taxonomy'])\n",
    "\n",
    "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
    "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
    "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
    "            # print(dict[\"taxonomy_similarity_sbert\"])\n",
    "\n",
    "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
    "            # print(len(dict['target_sequence']))\n",
    "            # print(len(dict['source_sequence']))\n",
    "            # print(dict['target_sequence'])\n",
    "            # print(dict['source_sequence'])# not inside bracket\n",
    "            # print(dict['target_taxonomy'])\n",
    "            # print(dict['source_taxonomy'])\n",
    "\n",
    "            #takes very long\n",
    "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
    "\n",
    "            #This part gives trouble\n",
    "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
    "        baseline_results.append(dict)\n",
    "    return baseline_results\n",
    "\n",
    "\n",
    "baseline_rag_missing_dict = check_missing_index(PATH_BASELINE_RAG, baselines[0])\n",
    "baseline_norag_missing_dict = check_missing_index(PATH_BASELINE_NORAG, baselines[1])\n",
    "baseline_1direct_missing_dict = check_missing_index(PATH_BASELINE_1DIRECT, baselines[2])\n",
    "baseline_1goalmediation_missing_dict = check_missing_index(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
    "\n",
    "print(len(baseline_rag_missing_dict))\n",
    "print(baseline_rag_missing_dict)\n",
    "print(len(baseline_norag_missing_dict))\n",
    "print(baseline_norag_missing_dict)\n",
    "print(len(baseline_1direct_missing_dict))\n",
    "print(baseline_1direct_missing_dict)\n",
    "print(len(baseline_1goalmediation_missing_dict))\n",
    "print(baseline_1goalmediation_missing_dict)\n",
    "\n",
    "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
    "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
    "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
    "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
    "\n",
    "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
    "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
    "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
    "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cee638",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'isin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MANUAL-GOLD, CH-SILVER, ELSE-BRONZE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# GOLD (manual)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# filtered_df = df[df[\"v1\"].isin(mylist)]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gold_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdcd09fa4-afe2-4a0d-9703-83af2867ebd3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m46e07357-6946-4ff0-ba36-ae11840bdc39\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabab0e69-f7e4-40c1-aa58-375798df487a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m ]\n\u001b[0;32m---> 29\u001b[0m baseline_rag_list \u001b[38;5;241m=\u001b[39m [df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_uid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(gold_list)] \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m baseline_rag_list]\n\u001b[1;32m     30\u001b[0m baseline_norag_list \u001b[38;5;241m=\u001b[39m baseline_norag_list[baseline_norag_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_uid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(gold_list)]\n\u001b[1;32m     31\u001b[0m baseline_1direct_list \u001b[38;5;241m=\u001b[39m baseline_1direct_list[baseline_1direct_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_uid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(gold_list)]\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MANUAL-GOLD, CH-SILVER, ELSE-BRONZE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# GOLD (manual)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# filtered_df = df[df[\"v1\"].isin(mylist)]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gold_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdcd09fa4-afe2-4a0d-9703-83af2867ebd3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m46e07357-6946-4ff0-ba36-ae11840bdc39\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabab0e69-f7e4-40c1-aa58-375798df487a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m ]\n\u001b[0;32m---> 29\u001b[0m baseline_rag_list \u001b[38;5;241m=\u001b[39m [df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource_uid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m(gold_list)] \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m baseline_rag_list]\n\u001b[1;32m     30\u001b[0m baseline_norag_list \u001b[38;5;241m=\u001b[39m baseline_norag_list[baseline_norag_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_uid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(gold_list)]\n\u001b[1;32m     31\u001b[0m baseline_1direct_list \u001b[38;5;241m=\u001b[39m baseline_1direct_list[baseline_1direct_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_uid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(gold_list)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'isin'"
     ]
    }
   ],
   "source": [
    "# MANUAL-GOLD, CH-SILVER, ELSE-BRONZE\n",
    "\n",
    "# GOLD (manual)\n",
    "# filtered_df = df[df[\"v1\"].isin(mylist)]\n",
    "gold_list = [\n",
    "\"dcd09fa4-afe2-4a0d-9703-83af2867ebd3\",\n",
    "\"46e07357-6946-4ff0-ba36-ae11840bdc39\",\n",
    "\"026dac2d-2ab3-4f9c-9e1d-6198db4fb080\",\n",
    "\"2f46d1e6-2a85-4d46-b955-10c2eded661c\",\n",
    "\"14bcb17c-f70a-41d5-b10d-294388084dfc\",\n",
    "\"487d752c-6e22-43e3-9c08-627bc2a6c6d4\",\n",
    "\"543e4c99-5d9f-407d-be75-c397d633fe56\",\n",
    "\"24ba7993-7fc8-4447-afd5-7ff6d548b11a\",\n",
    "\"e09a667f-04bc-49b5-8246-daf248a29174\",\n",
    "\"b17ff269-ec2d-4ad8-88aa-b00b75921427\",\n",
    "\"58b2a4a4-b721-4753-bfc3-478cdb5bd1a8\",\n",
    "\"28e0affc-cacb-4db8-ab32-dfc16931b86a\",\n",
    "\"e72082e8-f9e6-42ac-ac45-de30f9adee9d\",\n",
    "\"f0204f83-ea03-4c33-b7e7-13d2188ab3e5\",\n",
    "\"9fabfbc8-1d5c-495e-9bb2-03795f0145ae\",\n",
    "\"01ce4fd6-197a-4792-8778-775b03780369\",\n",
    "\"47bb1fd4-d41f-42b4-8d0c-29c4e9fdff9f\",\n",
    "\"7e8d03f2-2ff9-431d-af81-e5ffcd954a63\",\n",
    "\"89857b33-fa50-469a-bbb3-91c8ab655931\",\n",
    "\"5c2e910c-84e0-4042-b5d6-880a731c3e67\",\n",
    "\"737e9619-7768-407c-8a4f-6fe1e8d61f04\",\n",
    "\"abab0e69-f7e4-40c1-aa58-375798df487a\"\n",
    "]\n",
    "baseline_rag_list = [df[df['source_uid'].isin(gold_list)] for df in baseline_rag_list]\n",
    "baseline_norag_list = baseline_norag_list[baseline_norag_list[\"source_uid\"].isin(gold_list)]\n",
    "baseline_1direct_list = baseline_1direct_list[baseline_1direct_list[\"source_uid\"].isin(gold_list)]\n",
    "baseline_1goalmediation_list = baseline_1goalmediation_list[baseline_1goalmediation_list[\"source_uid\"].isin(gold_list)]\n",
    "# SILVER (0)\n",
    "silver_list = [\n",
    "\"02a06bf1-51b8-4902-b088-573e29fcd7ec\",\n",
    "\"1dc85adb-fbdd-4275-b9cf-42976acb4d14\",\n",
    "\"2978ddbc-cdc9-4bfa-9a7c-4bf056904010\",\n",
    "\"2bc7d6fa-a02e-4367-b316-d6b4e8a2ce3f\",\n",
    "\"31d6fe77-da70-42da-8f47-66bb79b9285b\",\n",
    "\"321b5e21-2951-40c9-a2f9-6ce0c145cfb8\",\n",
    "\"341b5211-bb72-4bec-bd3d-c0d518887960\",\n",
    "\"35080724-6604-401c-8b06-19b7cece3d45\",\n",
    "\"38a7b760-56f9-4565-8b70-f8dad5768ace\",\n",
    "\"5461912b-69cd-40d7-8f79-50832f92f049\",\n",
    "\"6dafeac7-75b6-4d69-96f7-d08708a0a99e\",\n",
    "\"98434f4c-6216-4067-ad59-4a89cb47bb9b\",\n",
    "\"a267b011-b1db-4e3c-aa49-438e2afdd6dc\",\n",
    "\"b83285c5-0b88-4ced-a52e-5c34ea371507\",\n",
    "\"debfb68a-eae2-464e-847a-cd3fea23f3ca\",\n",
    "\"e4ad6fd7-2e3e-4991-b392-a0056f702286\",\n",
    "\"e6231d1a-1f7f-4198-a499-7635509adfaf\",\n",
    "\"ec3556de-be79-4ad4-aa0f-eaca48abb5d5\",\n",
    "\"ed60dcdb-b273-44e7-b5dc-f9527d7c403f\",\n",
    "\"f5ac654b-8f39-427b-856f-4a9a2d4a3020\",\n",
    "\"fea524d4-a1b6-466c-ac48-8777c3fd173d\"\n",
    "]\n",
    "baseline_rag_list = baseline_rag_list[baseline_rag_list[\"source_uid\"].isin(silver_list)]\n",
    "baseline_norag_list = baseline_norag_list[baseline_norag_list[\"source_uid\"].isin(silver_list)]\n",
    "baseline_1direct_list = baseline_1direct_list[baseline_1direct_list[\"source_uid\"].isin(silver_list)]\n",
    "baseline_1goalmediation_list = baseline_1goalmediation_list[baseline_1goalmediation_list[\"source_uid\"].isin(silver_list)]\n",
    "# BRONZE\n",
    "bronze_list =[\n",
    "\"1a894d3c-b3ef-448a-a3de-2b38677cef36\",\n",
    "\"29e00040-6e0f-4f0e-816d-1ac97c1e5485\",\n",
    "\"2ba0becb-58c2-43a1-97bb-7e153a34eb47\",\n",
    "\"2c27b5f1-4af6-49ad-a43c-3efb0c150868\",\n",
    "\"2da5c1ee-bd40-406d-83a7-2f3d93293949\",\n",
    "\"3728f856-0d47-4614-824f-37b6dda8e357\",\n",
    "\"3ec3eab7-842d-409d-8866-42ddcbd24cd9\",\n",
    "\"4fa75795-ddc4-4582-9715-bb7887439263\",\n",
    "\"56fe0c73-77c4-40d9-a687-b2df28d5f7d7\",\n",
    "\"5c15607b-96af-4503-84b4-d1745f3a3ae0\",\n",
    "\"6628a2fb-19e2-4fe5-aedb-92fe5ceee9c9\",\n",
    "\"690f58f1-f18c-4415-bab0-787c2f83d051\",\n",
    "\"6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\",\n",
    "\"748536e4-636a-4dc6-b1a7-d9cbfdc1cffd\",\n",
    "\"892629b0-61eb-425d-97f4-7d213074c435\",\n",
    "\"907fd0e7-6821-4e2d-9c62-6d7afad5a9d1\",\n",
    "\"a6419de9-1e40-4793-b21b-9c8d9038835a\",\n",
    "\"ab7ed4f7-10ee-4ccb-bb21-4853c9018b1e\",\n",
    "\"ae2d99c2-1720-4354-bc4d-f7bc3e4ee28d\",\n",
    "\"b4072935-56a6-4765-bb4d-d5f6bbeb95b9\",\n",
    "\"cf95d6a4-6ad7-462c-9700-9f04bd993667\",\n",
    "\"d7a2e92e-dc74-4e79-be04-a86f829fc3ec\",\n",
    "\"daf5384b-ea5c-4cce-bb8a-540a360075bf\",\n",
    "\"e250017c-16ff-4825-9c30-160f391e1549\",\n",
    "\"edc1869c-8a97-44fd-ab47-63fda4a54df9\",\n",
    "\"grp-690f58f1-f18c-4415-bab0-787c2f83d051\",\n",
    "\"grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\",\n",
    "\"grp-ffd863cb-f06b-404e-a013-54acb61f1ed9\"\n",
    "]\n",
    "baseline_rag_list = baseline_rag_list[baseline_rag_list[\"source_uid\"].isin(bronze_list)]\n",
    "baseline_norag_list = baseline_norag_list[baseline_norag_list[\"source_uid\"].isin(bronze_list)]\n",
    "baseline_1direct_list = baseline_1direct_list[baseline_1direct_list[\"source_uid\"].isin(bronze_list)]\n",
    "baseline_1goalmediation_list = baseline_1goalmediation_list[baseline_1goalmediation_list[\"source_uid\"].isin(bronze_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcc30a",
   "metadata": {},
   "source": [
    "## Perform Numerical Calculation of Results\n",
    "\n",
    "### base results\n",
    "- pairwise scene similarity\n",
    "- seq2seq similarity\n",
    "- seq2seq taxonomy similarity\n",
    "### plot\n",
    "- per scenario similarity analysis\n",
    "- per augmentation, per scenario similarity analysis\n",
    "- per scenario similarity vs similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f81421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved baseline list at evaluation_result_v4/rag_dict.pkl\n",
      "saved baseline list at evaluation_result_v4/norag_dict.pkl\n",
      "saved baseline list at evaluation_result_v4/1direct_dict.pkl\n",
      "saved baseline list at evaluation_result_v4/1goalmediation_dict.pkl\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563     True\n",
      "564    False\n",
      "565     True\n",
      "566    False\n",
      "567     True\n",
      "Name: sequence_boolean, Length: 568, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563    False\n",
      "564     True\n",
      "565    False\n",
      "566    False\n",
      "567    False\n",
      "Name: sequence_boolean, Length: 568, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563     True\n",
      "564     True\n",
      "565     True\n",
      "566     True\n",
      "567     True\n",
      "Name: taxonomy_boolean, Length: 568, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563     True\n",
      "564     True\n",
      "565     True\n",
      "566     True\n",
      "567     True\n",
      "Name: taxonomy_boolean, Length: 568, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_883290/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n",
      "/tmp/ipykernel_883290/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n",
      "/tmp/ipykernel_883290/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n",
      "/tmp/ipykernel_883290/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mask_nan_df(df):\n",
    "    mask = df.isna().any(axis=1)\n",
    "    df.loc[mask, :] = np.nan \n",
    "    \n",
    "def mask_nan_df_or_condition(df, columns_to_check):\n",
    "    '''\n",
    "    input: columns_to_check = [\"col1\", \"col2\"]\n",
    "    '''\n",
    "    mask = df[columns_to_check].isna().any(axis=1)\n",
    "    df.loc[mask, :] = np.nan    \n",
    "\n",
    "def save_baseline_list(path, baseline_list):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(baseline_list, f)\n",
    "        print(f\"saved baseline list at {path}\")\n",
    "\n",
    "# turn list of dictionary into dataframe\n",
    "# df_rag = pd.DataFrame(baseline_rag_list)\n",
    "\n",
    "\n",
    "df_rag = pd.DataFrame(baseline_rag_list)\n",
    "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
    "\n",
    "df_norag = pd.DataFrame(baseline_norag_list)\n",
    "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
    "\n",
    "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
    "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
    "# print(df_1direct.head())\n",
    "\n",
    "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
    "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
    "# print(df_1goalmediation.head())\n",
    "\n",
    "\n",
    "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
    "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
    "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
    "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
    "\n",
    "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
    "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
    "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
    "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
    "\n",
    "\n",
    "print(df_rag.shape[0])\n",
    "print(df_norag.shape[0])\n",
    "print(df_1direct.shape[0])\n",
    "print(df_1goalmediation.shape[0])\n",
    "\n",
    "print(df_rag['sequence_boolean'])\n",
    "print(df_norag['sequence_boolean'])\n",
    "\n",
    "print(df_rag['taxonomy_boolean'])\n",
    "print(df_norag['taxonomy_boolean'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e360a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "168\n",
      "224\n",
      "176\n",
      "168\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "# MANUAL-GOLD, CH-SILVER, ELSE-BRONZE\n",
    "\n",
    "# GOLD (manual)\n",
    "# filtered_df = df[df[\"v1\"].isin(mylist)]\n",
    "gold_list = [\n",
    "\"dcd09fa4-afe2-4a0d-9703-83af2867ebd3\",\n",
    "\"46e07357-6946-4ff0-ba36-ae11840bdc39\",\n",
    "\"026dac2d-2ab3-4f9c-9e1d-6198db4fb080\",\n",
    "\"2f46d1e6-2a85-4d46-b955-10c2eded661c\",\n",
    "\"14bcb17c-f70a-41d5-b10d-294388084dfc\",\n",
    "\"487d752c-6e22-43e3-9c08-627bc2a6c6d4\",\n",
    "\"543e4c99-5d9f-407d-be75-c397d633fe56\",\n",
    "\"24ba7993-7fc8-4447-afd5-7ff6d548b11a\",\n",
    "\"e09a667f-04bc-49b5-8246-daf248a29174\",\n",
    "\"b17ff269-ec2d-4ad8-88aa-b00b75921427\",\n",
    "\"58b2a4a4-b721-4753-bfc3-478cdb5bd1a8\",\n",
    "\"28e0affc-cacb-4db8-ab32-dfc16931b86a\",\n",
    "\"e72082e8-f9e6-42ac-ac45-de30f9adee9d\",\n",
    "\"f0204f83-ea03-4c33-b7e7-13d2188ab3e5\",\n",
    "\"9fabfbc8-1d5c-495e-9bb2-03795f0145ae\",\n",
    "\"01ce4fd6-197a-4792-8778-775b03780369\",\n",
    "\"47bb1fd4-d41f-42b4-8d0c-29c4e9fdff9f\",\n",
    "\"7e8d03f2-2ff9-431d-af81-e5ffcd954a63\",\n",
    "\"89857b33-fa50-469a-bbb3-91c8ab655931\",\n",
    "\"5c2e910c-84e0-4042-b5d6-880a731c3e67\",\n",
    "\"737e9619-7768-407c-8a4f-6fe1e8d61f04\",\n",
    "\"abab0e69-f7e4-40c1-aa58-375798df487a\"\n",
    "]\n",
    "import copy\n",
    "df_rag_g = copy.deepcopy(df_rag)\n",
    "df_norag_g = copy.deepcopy(df_norag)\n",
    "df_1direct_g = copy.deepcopy(df_1direct)\n",
    "df_1goalmediation_g = copy.deepcopy(df_1goalmediation)\n",
    "\n",
    "\n",
    "\n",
    "df_rag_gold = df_rag_g[df_rag_g['source_uid'].isin(gold_list)]\n",
    "df_norag_gold = df_norag_g[df_norag_g[\"source_uid\"].isin(gold_list)]\n",
    "df_1direct_gold = df_1direct_g[df_1direct_g[\"source_uid\"].isin(gold_list)]\n",
    "df_1goalmediation_gold = df_1goalmediation_g[df_1goalmediation_g[\"source_uid\"].isin(gold_list)]\n",
    "\n",
    "# SILVER (0)\n",
    "silver_list = [\n",
    "\"02a06bf1-51b8-4902-b088-573e29fcd7ec\",\n",
    "\"1dc85adb-fbdd-4275-b9cf-42976acb4d14\",\n",
    "\"2978ddbc-cdc9-4bfa-9a7c-4bf056904010\",\n",
    "\"2bc7d6fa-a02e-4367-b316-d6b4e8a2ce3f\",\n",
    "\"31d6fe77-da70-42da-8f47-66bb79b9285b\",\n",
    "\"321b5e21-2951-40c9-a2f9-6ce0c145cfb8\",\n",
    "\"341b5211-bb72-4bec-bd3d-c0d518887960\",\n",
    "\"35080724-6604-401c-8b06-19b7cece3d45\",\n",
    "\"38a7b760-56f9-4565-8b70-f8dad5768ace\",\n",
    "\"5461912b-69cd-40d7-8f79-50832f92f049\",\n",
    "\"6dafeac7-75b6-4d69-96f7-d08708a0a99e\",\n",
    "\"98434f4c-6216-4067-ad59-4a89cb47bb9b\",\n",
    "\"a267b011-b1db-4e3c-aa49-438e2afdd6dc\",\n",
    "\"b83285c5-0b88-4ced-a52e-5c34ea371507\",\n",
    "\"debfb68a-eae2-464e-847a-cd3fea23f3ca\",\n",
    "\"e4ad6fd7-2e3e-4991-b392-a0056f702286\",\n",
    "\"e6231d1a-1f7f-4198-a499-7635509adfaf\",\n",
    "\"ec3556de-be79-4ad4-aa0f-eaca48abb5d5\",\n",
    "\"ed60dcdb-b273-44e7-b5dc-f9527d7c403f\",\n",
    "\"f5ac654b-8f39-427b-856f-4a9a2d4a3020\",\n",
    "\"fea524d4-a1b6-466c-ac48-8777c3fd173d\"\n",
    "]\n",
    "df_rag_s = copy.deepcopy(df_rag)\n",
    "df_norag_s = copy.deepcopy(df_norag)\n",
    "df_1direct_s = copy.deepcopy(df_1direct)\n",
    "df_1goalmediation_s = copy.deepcopy(df_1goalmediation)\n",
    "\n",
    "df_rag_silver = df_rag_s[df_rag_s[\"source_uid\"].isin(silver_list)]\n",
    "df_norag_silver = df_norag_s[df_norag_s[\"source_uid\"].isin(silver_list)]\n",
    "df_1direct_silver = df_1direct_s[df_1direct_s[\"source_uid\"].isin(silver_list)]\n",
    "df_1goalmediation_silver = df_1goalmediation_s[df_1goalmediation_s[\"source_uid\"].isin(silver_list)]\n",
    "# BRONZE\n",
    "bronze_list =[\n",
    "\"1a894d3c-b3ef-448a-a3de-2b38677cef36\",\n",
    "\"29e00040-6e0f-4f0e-816d-1ac97c1e5485\",\n",
    "\"2ba0becb-58c2-43a1-97bb-7e153a34eb47\",\n",
    "\"2c27b5f1-4af6-49ad-a43c-3efb0c150868\",\n",
    "\"2da5c1ee-bd40-406d-83a7-2f3d93293949\",\n",
    "\"3728f856-0d47-4614-824f-37b6dda8e357\",\n",
    "\"3ec3eab7-842d-409d-8866-42ddcbd24cd9\",\n",
    "\"4fa75795-ddc4-4582-9715-bb7887439263\",\n",
    "\"56fe0c73-77c4-40d9-a687-b2df28d5f7d7\",\n",
    "\"5c15607b-96af-4503-84b4-d1745f3a3ae0\",\n",
    "\"6628a2fb-19e2-4fe5-aedb-92fe5ceee9c9\",\n",
    "\"690f58f1-f18c-4415-bab0-787c2f83d051\",\n",
    "\"6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\",\n",
    "\"748536e4-636a-4dc6-b1a7-d9cbfdc1cffd\",\n",
    "\"892629b0-61eb-425d-97f4-7d213074c435\",\n",
    "\"907fd0e7-6821-4e2d-9c62-6d7afad5a9d1\",\n",
    "\"a6419de9-1e40-4793-b21b-9c8d9038835a\",\n",
    "\"ab7ed4f7-10ee-4ccb-bb21-4853c9018b1e\",\n",
    "\"ae2d99c2-1720-4354-bc4d-f7bc3e4ee28d\",\n",
    "\"b4072935-56a6-4765-bb4d-d5f6bbeb95b9\",\n",
    "\"cf95d6a4-6ad7-462c-9700-9f04bd993667\",\n",
    "\"d7a2e92e-dc74-4e79-be04-a86f829fc3ec\",\n",
    "\"daf5384b-ea5c-4cce-bb8a-540a360075bf\",\n",
    "\"e250017c-16ff-4825-9c30-160f391e1549\",\n",
    "\"edc1869c-8a97-44fd-ab47-63fda4a54df9\",\n",
    "\"grp-690f58f1-f18c-4415-bab0-787c2f83d051\",\n",
    "\"grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\",\n",
    "\"grp-ffd863cb-f06b-404e-a013-54acb61f1ed9\"\n",
    "]\n",
    "df_rag_b = copy.deepcopy(df_rag)\n",
    "df_norag_b = copy.deepcopy(df_norag)\n",
    "df_1direct_b = copy.deepcopy(df_1direct)\n",
    "df_1goalmediation_b = copy.deepcopy(df_1goalmediation)\n",
    "\n",
    "df_rag_bronze = df_rag_b[df_rag_b[\"source_uid\"].isin(bronze_list)]\n",
    "df_norag_bronze = df_norag_b[df_norag_b[\"source_uid\"].isin(bronze_list)]\n",
    "df_1direct_bronze = df_1direct_b[df_1direct_b[\"source_uid\"].isin(bronze_list)]\n",
    "df_1goalmediation_bronze = df_1goalmediation_b[df_1goalmediation_b[\"source_uid\"].isin(bronze_list)]\n",
    "\n",
    "print(df_rag.shape[0])\n",
    "\n",
    "print(df_rag_gold.shape[0])\n",
    "print(df_norag_gold.shape[0])\n",
    "print(df_1direct_gold.shape[0])\n",
    "print(df_1goalmediation_gold.shape[0])\n",
    "\n",
    "print(df_rag_silver.shape[0])\n",
    "print(df_rag_bronze.shape[0])\n",
    "\n",
    "print(df_1direct_gold.shape[0])\n",
    "print(df_1direct_silver.shape[0])\n",
    "print(df_1direct_bronze.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a828a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 52\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 59\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 75\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#======================\n",
    "#interactive cursor hover\n",
    "#======================\n",
    "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
    "    size2 = filtered_df.shape[0]\n",
    "\n",
    "    # Step 2: Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sc = ax.scatter(\n",
    "        filtered_df['inclusion_ratio'], \n",
    "        filtered_df['taxonomy_similarity_sbert'], \n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('Inclusion Ratio')\n",
    "    ax.set_ylabel('Taxonomy Similarity')\n",
    "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
    "\n",
    "    # Polynomial fit\n",
    "    N = 1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "    # Limits and layout\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # mplcursors for interactive tooltips\n",
    "    cursor = mplcursors.cursor(sc, hover=True)\n",
    "    \n",
    "    @cursor.connect(\"add\")\n",
    "    def on_add(sel):\n",
    "        idx = sel.index\n",
    "        # Customize the tooltip content here\n",
    "        sel.annotation.set_text(\n",
    "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
    "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
    "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
    "        )\n",
    "\n",
    "    plt.show()    \n",
    "    print(filtered_df.shape[0])\n",
    "    ffiltered_df = filtered_df[filtered_df['inclusion_ratio'] == 1]\n",
    "    print(f\"inclusion 1 with fails {ffiltered_df.shape[0]}\")\n",
    "    print(ffiltered_df['source_uid'].unique().tolist())\n",
    "    print(ffiltered_df['idx'].unique().tolist())\n",
    "\n",
    "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
    "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
    "    size1 = df.shape[0]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    print(size1, size2)\n",
    "\n",
    "    # Step 2: Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sc = ax.scatter(\n",
    "        filtered_df['inclusion_ratio'], \n",
    "        filtered_df['sequence_similarity_sbert'], \n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('Inclusion Ratio')\n",
    "    ax.set_ylabel('Sequence Similarity')\n",
    "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
    "\n",
    "    # Polynomial fit\n",
    "    N = 1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "    # Limits and layout\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # mplcursors for interactive tooltips\n",
    "    cursor = mplcursors.cursor(sc, hover=True)\n",
    "    \n",
    "    @cursor.connect(\"add\")\n",
    "    def on_add(sel):\n",
    "        idx = sel.index\n",
    "        # Customize the tooltip content here\n",
    "        sel.annotation.set_text(\n",
    "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
    "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
    "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
    "        )\n",
    " \n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "#======================\n",
    "#non interactive\n",
    "#======================\n",
    "def plot_taxonomy(df):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    # df = df.dropna()\n",
    "    mybool = True\n",
    "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    print(filtered_df.shape[0])\n",
    "    # Step 2: Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
    "    plt.xlabel('Inclusion Ratio')\n",
    "    plt.ylabel('Taxonomy Similarity')\n",
    "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
    "\n",
    "\n",
    "    #Generate smooth x values for curve plotting\n",
    "    N=1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "\n",
    "    plt.xlim(0, 1.1)\n",
    "    plt.ylim(0, 1.1)  \n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "def plot_sequence(df):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    mybool = True\n",
    "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
    "    size2 = filtered_df.shape[0]\n",
    "\n",
    "    # filtered_df = df\n",
    "\n",
    "    # Step 2: Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
    "    plt.xlabel('Inclusion Ratio')\n",
    "    plt.ylabel('Sequence Similarity')\n",
    "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
    "\n",
    "    # Generate smooth x values for curve plotting\n",
    "    N=1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "    plt.xlim(0, 1.1)\n",
    "    plt.ylim(0, 1.1)  \n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "# plot_taxonomy_cursor(df_rag, True)\n",
    "# plot_taxonomy_cursor(df_rag, False)\n",
    "# plot_taxonomy_cursor(df_norag, True)\n",
    "# plot_taxonomy_cursor(df_norag, False)\n",
    "# plot_taxonomy_cursor(df_norag)\n",
    "\n",
    "# plot_taxonomy_cursor(df_rag_gold, True)\n",
    "# plot_taxonomy_cursor(df_rag_gold, False)\n",
    "# plot_taxonomy_cursor(df_norag_gold, True)\n",
    "# plot_taxonomy_cursor(df_norag_gold, False)\n",
    "\n",
    "# plot_taxonomy_cursor(df_rag_silver, True)\n",
    "# plot_taxonomy_cursor(df_rag_silver, False)\n",
    "# plot_taxonomy_cursor(df_norag_silver, True)\n",
    "# plot_taxonomy_cursor(df_norag_silver, False)\n",
    "\n",
    "# plot_taxonomy_cursor(df_rag_bronze, True)\n",
    "# plot_taxonomy_cursor(df_rag_bronze, False)\n",
    "# plot_taxonomy_cursor(df_norag_bronze, True)\n",
    "# plot_taxonomy_cursor(df_norag_bronze, False)\n",
    "\n",
    "\n",
    "\n",
    "# plot_sequence_cursor(df_rag, True)\n",
    "# plot_sequence_cursor(df_norag, True)\n",
    "# plot_sequence_cursor(df_1direct, False)\n",
    "# plot_sequence_cursor(df_1goalmediation, True)\n",
    "\n",
    "\n",
    "# plot_sequence_cursor(df_rag_gold, True)\n",
    "# plot_sequence_cursor(df_rag_gold, False)\n",
    "# plot_sequence_cursor(df_norag_gold, True)\n",
    "# plot_sequence_cursor(df_norag_gold, False)\n",
    "plot_sequence_cursor(df_1goalmediation_gold, True)\n",
    "# plot_sequence_cursor(df_1goalmediation_gold, False)\n",
    "\n",
    "# plot_sequence_cursor(df_rag_silver, True)\n",
    "# plot_sequence_cursor(df_rag_silver, False)\n",
    "# plot_sequence_cursor(df_norag_silver, True)\n",
    "plot_sequence_cursor(df_1goalmediation_silver, True)\n",
    "# plot_sequence_cursor(df_1goalmediation_silver, False)\n",
    "\n",
    "\n",
    "# plot_sequence_cursor(df_rag_bronze, True)\n",
    "# plot_sequence_cursor(df_rag_bronze, False)\n",
    "# plot_sequence_cursor(df_norag_bronze, True)\n",
    "# plot_sequence_cursor(df_norag_bronze, False)\n",
    "plot_sequence_cursor(df_1goalmediation_bronze, True)\n",
    "# plot_sequence_cursor(df_1goalmediation_bronze, False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a3da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mplcursors\n",
    "\n",
    "# Dummy DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'inclusion_ratio': np.random.rand(10),\n",
    "    'sequence_similarity_sbert': np.random.rand(10),\n",
    "    'taxonomy_boolean': [True] * 10,\n",
    "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
    "})\n",
    "\n",
    "# plot_sequence_cursor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568 555 202 121\n",
      "568 525 177 109\n",
      "44\n",
      "idx\n",
      "idx: 13, 0.75, source_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080, target_uid: 2bc7d6fa-a02e-4367-b316-d6b4e8a2ce3f\n",
      "idx: 28, 0.50, source_uid: 14bcb17c-f70a-41d5-b10d-294388084dfc, target_uid: 2da5c1ee-bd40-406d-83a7-2f3d93293949\n",
      "idx: 34, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 71, 0.35, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 113, 0.50, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 114, 0.40, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 213, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 214, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 229, 0.57, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 230, 0.71, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 266, 0.33, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 269, 0.45, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 303, 1.00, source_uid: 748536e4-636a-4dc6-b1a7-d9cbfdc1cffd, target_uid: abab0e69-f7e4-40c1-aa58-375798df487a\n",
      "idx: 372, 0.78, source_uid: ab7ed4f7-10ee-4ccb-bb21-4853c9018b1e, target_uid: debfb68a-eae2-464e-847a-cd3fea23f3ca\n",
      "idx: 414, 0.75, source_uid: b83285c5-0b88-4ced-a52e-5c34ea371507, target_uid: e72082e8-f9e6-42ac-ac45-de30f9adee9d\n",
      "idx: 479, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 498, 0.29, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "idx: 502, 0.57, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "inclusion_ratio\n",
      "idx: 498, 0.29, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "idx: 266, 0.33, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 71, 0.35, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 114, 0.40, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 34, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 269, 0.45, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 113, 0.50, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 28, 0.50, source_uid: 14bcb17c-f70a-41d5-b10d-294388084dfc, target_uid: 2da5c1ee-bd40-406d-83a7-2f3d93293949\n",
      "idx: 502, 0.57, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "idx: 229, 0.57, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 213, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 214, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 230, 0.71, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 13, 0.75, source_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080, target_uid: 2bc7d6fa-a02e-4367-b316-d6b4e8a2ce3f\n",
      "idx: 414, 0.75, source_uid: b83285c5-0b88-4ced-a52e-5c34ea371507, target_uid: e72082e8-f9e6-42ac-ac45-de30f9adee9d\n",
      "idx: 372, 0.78, source_uid: ab7ed4f7-10ee-4ccb-bb21-4853c9018b1e, target_uid: debfb68a-eae2-464e-847a-cd3fea23f3ca\n",
      "idx: 479, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 303, 1.00, source_uid: 748536e4-636a-4dc6-b1a7-d9cbfdc1cffd, target_uid: abab0e69-f7e4-40c1-aa58-375798df487a\n",
      "idx\n",
      "idx: 36, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 70, 0.31, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 196, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 197, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 210, 0.59, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 261, 0.25, source_uid: 6628a2fb-19e2-4fe5-aedb-92fe5ceee9c9, target_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b\n",
      "idx: 338, 0.67, source_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b, target_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667\n",
      "idx: 347, 0.67, source_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae, target_uid: d7a2e92e-dc74-4e79-be04-a86f829fc3ec\n",
      "idx: 421, 0.46, source_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667, target_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5\n",
      "idx: 476, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 477, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 478, 0.75, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 549, 0.47, source_uid: grp-690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 28e0affc-cacb-4db8-ab32-dfc16931b86a\n",
      "idx: 559, 0.62, source_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585, target_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010\n",
      "inclusion_ratio\n",
      "idx: 261, 0.25, source_uid: 6628a2fb-19e2-4fe5-aedb-92fe5ceee9c9, target_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b\n",
      "idx: 70, 0.31, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 36, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 421, 0.46, source_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667, target_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5\n",
      "idx: 549, 0.47, source_uid: grp-690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 28e0affc-cacb-4db8-ab32-dfc16931b86a\n",
      "idx: 210, 0.59, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 559, 0.62, source_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585, target_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010\n",
      "idx: 338, 0.67, source_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b, target_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667\n",
      "idx: 347, 0.67, source_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae, target_uid: d7a2e92e-dc74-4e79-be04-a86f829fc3ec\n",
      "idx: 478, 0.75, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 196, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 197, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 477, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 476, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_taxdf(df:dict):\n",
    "    size0 = df.shape[0]\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
    "    size3 = filtered_df.shape[0]\n",
    "\n",
    "    print(f\"{size0} {size1} {size2} {size3}\")\n",
    "    return filtered_df\n",
    "\n",
    "filtered_df_rag = filter_taxdf(df_rag)\n",
    "filtered_df_norag = filter_taxdf(df_norag)\n",
    "\n",
    "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
    "    filtered_df = df[df[sbertitem] > min]\n",
    "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
    "    size = filtered_df.shape[0]\n",
    "    # print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
    "    print(\"idx\")\n",
    "    filtered_df = filtered_df.sort_values(by='idx')\n",
    "    for i in range(size):\n",
    "        print(f\"idx: {filtered_df.iloc[i]['idx']}, {filtered_df.iloc[i]['inclusion_ratio']:.2f}, source_uid: {filtered_df.iloc[i]['source_uid']}, target_uid: {filtered_df.iloc[i]['target_uid']}\")\n",
    "\n",
    "    print(\"inclusion_ratio\")\n",
    "    filtered_df = filtered_df.sort_values(by='inclusion_ratio')\n",
    "    for i in range(size):\n",
    "        print(f\"idx: {filtered_df.iloc[i]['idx']}, {filtered_df.iloc[i]['inclusion_ratio']:.2f}, source_uid: {filtered_df.iloc[i]['source_uid']}, target_uid: {filtered_df.iloc[i]['target_uid']}\")\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
    "    '''\n",
    "    k:keyname\n",
    "    '''\n",
    "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
    "\n",
    "\n",
    "\n",
    "# find passed true rags and lookat same index\n",
    "common_idx = set(filtered_df_rag['idx']) & set(filtered_df_norag['idx'])\n",
    "df_common = filtered_df_rag[filtered_df_rag['idx'].isin(common_idx)]\n",
    "print(df_common.shape[0])\n",
    "df_common1 = filter_by_sbert(df_common, 'taxonomy_similarity_sbert', 0.95, 1.0)\n",
    "df_common2 = filter_by_sbert(df_common, 'taxonomy_similarity_sbert', 0.90, 0.95)\n",
    "\n",
    "\n",
    "# # for 1.0 both seq and taxonomy survives\n",
    "# print(\"sbert 1.0\")\n",
    "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.95, 1.0)\n",
    "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
    "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.95,1.0)\n",
    "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.95,1.0)\n",
    "\n",
    "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
    "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
    "# more_common_list1 = list(set(common_rag) & set(common_norag))\n",
    "# print(f\"{len(common_rag)} {common_rag}\")\n",
    "# print(f\"{len(common_norag)} {common_norag}\")\n",
    "# print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
    "\n",
    "# print(\"sbert 0.65-0.75\")\n",
    "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
    "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
    "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
    "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
    "\n",
    "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
    "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
    "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
    "# print(f\"{len(common_rag)} {common_rag}\")\n",
    "# print(f\"{len(common_norag)} {common_norag}\")\n",
    "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
    "\n",
    "# print(\"sbert 0.5-0.5\")\n",
    "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
    "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
    "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
    "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
    "\n",
    "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
    "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
    "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
    "# print(f\"{len(common_rag)} {common_rag}\")\n",
    "# print(f\"{len(common_norag)} {common_norag}\")\n",
    "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
    "# # find uid that made through both booleans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%matplotlib qt\n",
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "import json\n",
      "import torch\n",
      "import matplotlib.pyplot as plt\n",
      "import mplcursors\n",
      "from sklearn.manifold import TSNE\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "\n",
      "import pickle\n",
      "\n",
      "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
      "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
      "from util import util_constants\n",
      "from util import util_funcs\n",
      "import f4_evaluate.evaluate_scene as evaluate_scene\n",
      "import f1_init.database_init as database_init\n",
      "import f1_init.agent_init as agent_init\n",
      "import f1_init.constants_init as constants_init\n",
      "\n",
      "#Computing similarity\n",
      "import json\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "import numpy as np\n",
      "from numpy.linalg import norm\n",
      "import ast\n",
      "import pandas as pd\n",
      "\n",
      "#PATHS\n",
      "PATH_CURR_FOLDER = os.path.abspath('') \n",
      "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
      "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
      "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
      "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
      "\n",
      "#PAIRSIM DATA\n",
      "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
      "\n",
      "#AUGMENTED DATA PATH\n",
      "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
      "TEST_SPATIAL_ANNOTATION_V2_PATH = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_v2/'\n",
      "\n",
      "#BASELINE RESULT PATHS\n",
      "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag/'))\n",
      "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag/'))\n",
      "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1direct/'))\n",
      "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1goalmediation/'))\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 * 8 #8levels, 8files\n",
      "\n",
      "    # for i in range(length):\n",
      "    for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "        dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "        dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "        dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "\n",
      "\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(len(baseline_norag_list))\n",
      "print(len(baseline_rag_list))\n",
      "\n",
      "print(len(baseline_1direct_list))\n",
      "print(len(baseline_1goalmediation_list))\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df(df_norag)\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df(df_norag)\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "%matplotlib notebook\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "plot_sequence_cursor(df)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "plot_sequence(df_1direct)\n",
      "plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    df = df.dropna()\n",
      "    mybool = False\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "plot_sequence(df_1direct)\n",
      "plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "plot_sequence(df_1direct)\n",
      "plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "        dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "        dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "        dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(len(baseline_rag_list))\n",
      "print(len(baseline_norag_list))\n",
      "print(len(baseline_1direct_list))\n",
      "print(len(baseline_1goalmediation_list))\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "        dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "        dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "        dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(len(baseline_rag_list))\n",
      "print(len(baseline_norag_list))\n",
      "print(len(baseline_1direct_list))\n",
      "print(len(baseline_1goalmediation_list))\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "%matplotlib qt\n",
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "import json\n",
      "import torch\n",
      "import matplotlib.pyplot as plt\n",
      "import mplcursors\n",
      "from sklearn.manifold import TSNE\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "\n",
      "import pickle\n",
      "\n",
      "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
      "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
      "from util import util_constants\n",
      "from util import util_funcs\n",
      "import f4_evaluate.evaluate_scene as evaluate_scene\n",
      "import f1_init.database_init as database_init\n",
      "import f1_init.agent_init as agent_init\n",
      "import f1_init.constants_init as constants_init\n",
      "\n",
      "#Computing similarity\n",
      "import json\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "import numpy as np\n",
      "from numpy.linalg import norm\n",
      "import ast\n",
      "import pandas as pd\n",
      "\n",
      "#PATHS\n",
      "PATH_CURR_FOLDER = os.path.abspath('') \n",
      "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
      "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
      "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
      "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
      "\n",
      "#PAIRSIM DATA\n",
      "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
      "\n",
      "#AUGMENTED DATA PATH\n",
      "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
      "TEST_SPATIAL_ANNOTATION_V2_PATH = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_v2/'\n",
      "\n",
      "#BASELINE RESULT PATHS\n",
      "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag/'))\n",
      "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag/'))\n",
      "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1direct/'))\n",
      "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1goalmediation/'))\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            # dict[\"sequence_boolean\"] = False\n",
      "            # dict[\"taxonomy_boolean\"] = False \n",
      "            continue\n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['sequence_boolean'])\n",
      "print(df_norag['sequence_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['sequence_boolean'])\n",
      "print(df_norag['sequence_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['sequence_boolean'])\n",
      "print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict[\"taxonomy_boolean\"]} {dict[\"sequence_boolean\"]}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict[\"taxonomy_boolean\"]} {dict[\"sequence_boolean\"]}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "    print(source_tax)\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "    print(entry.get('source_taxnomy'))\n",
      "    print(source_tax)\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "    print(entry.get('source_taxnomy'))\n",
      "    print(source_tax)\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag, True)\n",
      "plot_taxonomy_cursor(df_rag, False)\n",
      "plot_taxonomy_cursor(df_norag, True)\n",
      "plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "# plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "%matplotlib qt\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "# plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "print(df_1direct['sequence_boolean'])\n",
      "print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "# print(df_rag['taxonomy_boolean'])\n",
      "# print(df_norag['taxonomy_boolean'])\n",
      "print(df_1direct['sequence_similarity_sbert'])\n",
      "print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "# print(df_rag['taxonomy_boolean'])\n",
      "# print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    # df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "print(df_1direct['sequence_similarity_sbert'])\n",
      "print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "print(df_1direct['sequence_boolean'])\n",
      "print(df_1goalmediation['sequence_boolean'])\n",
      "# print(df_rag['taxonomy_boolean'])\n",
      "# print(df_norag['taxonomy_boolean'])\n",
      "print(df_1direct['sequence_similarity_sbert'])\n",
      "print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "print(df_1direct['sequence_boolean'])\n",
      "print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "df_1direct_bool = df_1direct[df_1direct['sequence_boolean'] == True]\n",
      "print(df_1direct)\n",
      "# print(df_1direct['sequence_similarity_sbert'])\n",
      "# print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "# print(df_1direct['sequence_boolean'])\n",
      "# print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "df_1direct_bool = df_1direct[df_1direct['sequence_boolean'] == True]\n",
      "print(df_1direct)\n",
      "# print(df_1direct['sequence_similarity_sbert'])\n",
      "# print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "# print(df_1direct['sequence_boolean'])\n",
      "# print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "df_1direct_bool = df_1direct[df_1direct['sequence_boolean'] == True]\n",
      "print(df_1direct)\n",
      "\n",
      "df_1goalmediation_bool = df_1goalmediation[df_1goalmediation['sequence_boolean'] == True]\n",
      "print(df_1goalmediation_bool)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, False)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, False)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag, True)\n",
      "plot_taxonomy_cursor(df_rag, False)\n",
      "plot_taxonomy_cursor(df_norag, True)\n",
      "plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "# plot_sequence_cursor(df_1direct, False)\n",
      "# plot_sequence_cursor(df_1goalmediation, True)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', sequence_boolean])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size4 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size4 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    print(filtered_df['source_uid'])\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(filtered_df['source_uid'])\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_siimlarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_siimlarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_siimlarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_siimlarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_siimlarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_siimlarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_simlarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_simlarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_simlarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_simlarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_simlarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_simlarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "# print(\"sbert 1.0\")\n",
      "# # filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# # filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# # filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "# # filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def filter_common_uid(dict1:dict, dict2:dict):\n",
      "    common_dict = {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "    size = common_dict.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return common_dict\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "common_df_rag_tax = filter_common_uid(filtered_df_rag_tax, filtered_df_rag_seq )\n",
      "common_df_rag_tax = filter_common_uid(filtered_df_norag_tax, filtered_df_norag_seq )\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8, 0.899)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8, 0.899)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8, 0.899)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8, 0.899)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str)\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str)\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    # print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    # print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag, True)\n",
      "plot_taxonomy_cursor(df_rag, False)\n",
      "plot_taxonomy_cursor(df_norag, True)\n",
      "plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "# plot_sequence_cursor(df_1direct, False)\n",
      "# plot_sequence_cursor(df_1goalmediation, True)\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b91924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
