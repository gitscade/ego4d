{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325a1267",
   "metadata": {},
   "source": [
    "# Evaluate Plots V2\n",
    "\n",
    "test pair에 대한 iteration을 수행한다.\n",
    "\n",
    "1. pickle을 통해서 모든 아이템을 다 읽는다.\n",
    "2. 현재 source sequence를 읽는다.\n",
    "3. scene similarity를 읽는다.\n",
    "- mistral로 계산한 inclusion ratio\n",
    "- 직접 계산한 entity similarity\n",
    "\n",
    "4. action sequence similarity를 계산한다.\n",
    "- agent4 필터 통과와 상관없이 플롯\n",
    "- agent4 필터를 통과하면 플롯\n",
    "\n",
    "5. activity taxnomy similarity를 계산한다.\n",
    "- agent4 필터 통과와 상관없이 플롯\n",
    "- agent4 필터를 통과하면 플롯\n",
    "\n",
    "\n",
    "다음의 pandas colum을 구성한다. (568x13 정도 되나?)\n",
    "\n",
    "없는 곳은 None표시를 한다.\n",
    "\n",
    "source idx, target idx, \n",
    "augmentation_id, inclusion_ratio, entity_similarity\n",
    "goal_category, goal_description\n",
    "core activity_gt, core activity_inf\n",
    "sequence sim, taxonomy sim\n",
    "sequence bool, taxonomy bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c38f736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-root'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "from sklearn.manifold import TSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score\n",
    "\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
    "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
    "from util import util_constants\n",
    "from util import util_funcs\n",
    "import f4_evaluate.evaluate_scene as evaluate_scene\n",
    "import f1_init.database_init as database_init\n",
    "import f1_init.agent_init as agent_init\n",
    "import f1_init.constants_init as constants_init\n",
    "\n",
    "#Computing similarity\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "#PATHS\n",
    "PATH_CURR_FOLDER = os.path.abspath('') \n",
    "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
    "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
    "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
    "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
    "\n",
    "#PAIRSIM DATA\n",
    "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
    "\n",
    "#AUGMENTED DATA PATH\n",
    "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
    "TEST_SPATIAL_ANNOTATION_V2_PATH = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_v2/'\n",
    "\n",
    "#BASELINE RESULT PATHS\n",
    "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag/'))\n",
    "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag/'))\n",
    "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1direct/'))\n",
    "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1goalmediation/'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    try:          \n",
    "         with open(path, \"rb\") as f:\n",
    "             data = pickle.load(f)\n",
    "             return data\n",
    "    except:\n",
    "         return None\n",
    "    \n",
    "#=====================================\n",
    "# SIMILARITIES v1 SINGLE STRING SBERT MODEL\n",
    "#=====================================\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "def safe_parse_sequence(seq):\n",
    "    if seq is None:\n",
    "        return []\n",
    "    if isinstance(seq, list):\n",
    "        return seq\n",
    "    try:\n",
    "        return ast.literal_eval(seq)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(\"taxonomy safe parse value error\")\n",
    "        return []\n",
    "\n",
    "def safe_parse_taxonomy(tax):\n",
    "    if tax is None:\n",
    "        return {}\n",
    "    if isinstance(tax, dict):\n",
    "        return tax\n",
    "    try:\n",
    "        return json.loads(tax)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return {}\n",
    "\n",
    "def compute_similarities(entry, embed_model):\n",
    "    # --- Parse sequences ---\n",
    "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
    "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
    "\n",
    "    if not source_seq or not target_seq:\n",
    "        seq_similarity = 0.0\n",
    "    else:\n",
    "        source_seq_str = ' '.join(source_seq)\n",
    "        target_seq_str = ' '.join(target_seq)\n",
    "        source_seq_emb = embed_model.encode(source_seq_str)\n",
    "        target_seq_emb = embed_model.encode(target_seq_str)\n",
    "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
    "\n",
    "    # --- Parse taxonomies ---\n",
    "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
    "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
    "\n",
    "    if not source_tax or not target_tax:\n",
    "        tax_similarity = 0.0\n",
    "    else:\n",
    "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
    "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
    "        source_tax_emb = embed_model.encode(source_tax_str)\n",
    "        target_tax_emb = embed_model.encode(target_tax_str)\n",
    "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
    "\n",
    "    return seq_similarity, tax_similarity\n",
    "\n",
    "#=====================================\n",
    "# SIMILARITIES v2 WEIGHTED LINEAR TAXONOMY SEMANTICS MODEL\n",
    "# weight by level\n",
    "# Compare only values\n",
    "#=====================================\n",
    "\n",
    "\n",
    "#=====================================\n",
    "# SIMILARITIES v3 WEIGHTED SIMILARITY & GED MODEL\n",
    "# COMPLETELY DIFFERENT WEIGHT FOR insertion, deletion of nodes\n",
    "# Compare only values\n",
    "#====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12e164",
   "metadata": {},
   "source": [
    "## Read Results\n",
    "\n",
    "read a list of 568 pickle sets in 8 elements for 8 levels in augmentation\n",
    "\n",
    "make dictionary\n",
    "-fill every information\n",
    "-fill every calculatable information\n",
    "-save as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cdf074b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
    "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
    "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
    "    '''\n",
    "    func: make single baseline list\n",
    "\n",
    "    '''\n",
    "    baseline_result_path = baseline_result_path + \"/\"\n",
    "    baseline_results = []\n",
    "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    length = 71 * 8 #8levels, 8files\n",
    "\n",
    "    for i in range(length):\n",
    "    # for i in range(568):\n",
    "        # print(i)\n",
    "        dict = {\n",
    "            \"idx\":None,\"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"target_uid\": None, \"baseline\": None, \"augmode\": None, \n",
    "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
    "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
    "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
    "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
    "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
    "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
    "            }\n",
    "\n",
    "        prefix = f\"pair{i}_\"\n",
    "        augmode = i%len(augmodes)\n",
    "        # FILL RAW DATA\n",
    "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
    "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
    "        dict[\"idx\"] = i\n",
    "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
    "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
    "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
    "        dict[\"target_uid\"] = targetinfo_dict['target_uid']\n",
    "        dict[\"baseline\"] = baseline\n",
    "        dict[\"augmode\"] = augmode\n",
    "\n",
    "\n",
    "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
    "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
    "\n",
    "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
    "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
    "\n",
    "        \n",
    "        # based on baselines     \n",
    "        if baseline == \"1direct\":\n",
    "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
    "        if baseline == \"1goalmediation\":\n",
    "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
    "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
    "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
    "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
    "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
    "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
    "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
    "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
    "\n",
    "\n",
    "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
    "        if(booleans == None):\n",
    "            ## No values whatsover\n",
    "            dict[\"sequence_boolean\"] = False\n",
    "            dict[\"taxonomy_boolean\"] = False \n",
    "        else:\n",
    "            values = [\n",
    "                line.split(\":\")[1].strip()\n",
    "                for line in booleans.strip().splitlines()\n",
    "                if \":\" in line\n",
    "            ]\n",
    "            # print(values)\n",
    "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
    "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
    "            # print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
    "        \n",
    "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
    "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
    "        # SBERT for block level semantics\n",
    "\n",
    "        if dict['target_sequence'] != None:\n",
    "            \n",
    "            # Preprocess sequece to make sequence a single string\n",
    "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
    "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
    "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
    "            \n",
    "            # print(dict['source_taxonomy'])\n",
    "            # print(dict['target_taxonomy'])\n",
    "\n",
    "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
    "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
    "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
    "            # print(dict[\"taxonomy_similarity_sbert\"])\n",
    "\n",
    "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
    "            # print(len(dict['target_sequence']))\n",
    "            # print(len(dict['source_sequence']))\n",
    "            # print(dict['target_sequence'])\n",
    "            # print(dict['source_sequence'])# not inside bracket\n",
    "            # print(dict['target_taxonomy'])\n",
    "            # print(dict['source_taxonomy'])\n",
    "\n",
    "            #takes very long\n",
    "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
    "\n",
    "            #This part gives trouble\n",
    "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
    "        baseline_results.append(dict)\n",
    "    return baseline_results\n",
    "\n",
    "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
    "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
    "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
    "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
    "\n",
    "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
    "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
    "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
    "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcc30a",
   "metadata": {},
   "source": [
    "## Perform Numerical Calculation of Results\n",
    "\n",
    "### base results\n",
    "- pairwise scene similarity\n",
    "- seq2seq similarity\n",
    "- seq2seq taxonomy similarity\n",
    "### plot\n",
    "- per scenario similarity analysis\n",
    "- per augmentation, per scenario similarity analysis\n",
    "- per scenario similarity vs similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6f81421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved baseline list at evaluation_result_v4/rag_dict.pkl\n",
      "saved baseline list at evaluation_result_v4/norag_dict.pkl\n",
      "saved baseline list at evaluation_result_v4/1direct_dict.pkl\n",
      "saved baseline list at evaluation_result_v4/1goalmediation_dict.pkl\n",
      "568\n",
      "568\n",
      "568\n",
      "568\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563     True\n",
      "564    False\n",
      "565     True\n",
      "566    False\n",
      "567     True\n",
      "Name: sequence_boolean, Length: 568, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563    False\n",
      "564     True\n",
      "565    False\n",
      "566    False\n",
      "567    False\n",
      "Name: sequence_boolean, Length: 568, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563     True\n",
      "564     True\n",
      "565     True\n",
      "566     True\n",
      "567     True\n",
      "Name: taxonomy_boolean, Length: 568, dtype: bool\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "563     True\n",
      "564     True\n",
      "565     True\n",
      "566     True\n",
      "567     True\n",
      "Name: taxonomy_boolean, Length: 568, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3729869/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n",
      "/tmp/ipykernel_3729869/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n",
      "/tmp/ipykernel_3729869/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n",
      "/tmp/ipykernel_3729869/871926004.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, :] = np.nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mask_nan_df(df):\n",
    "    mask = df.isna().any(axis=1)\n",
    "    df.loc[mask, :] = np.nan \n",
    "    \n",
    "def mask_nan_df_or_condition(df, columns_to_check):\n",
    "    '''\n",
    "    input: columns_to_check = [\"col1\", \"col2\"]\n",
    "    '''\n",
    "    mask = df[columns_to_check].isna().any(axis=1)\n",
    "    df.loc[mask, :] = np.nan    \n",
    "\n",
    "def save_baseline_list(path, baseline_list):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(baseline_list, f)\n",
    "        print(f\"saved baseline list at {path}\")\n",
    "\n",
    "# turn list of dictionary into dataframe\n",
    "# df_rag = pd.DataFrame(baseline_rag_list)\n",
    "\n",
    "\n",
    "df_rag = pd.DataFrame(baseline_rag_list)\n",
    "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
    "\n",
    "df_norag = pd.DataFrame(baseline_norag_list)\n",
    "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
    "\n",
    "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
    "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
    "# print(df_1direct.head())\n",
    "\n",
    "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
    "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
    "# print(df_1goalmediation.head())\n",
    "\n",
    "\n",
    "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
    "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
    "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
    "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
    "\n",
    "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
    "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
    "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
    "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
    "\n",
    "\n",
    "print(df_rag.shape[0])\n",
    "print(df_norag.shape[0])\n",
    "print(df_1direct.shape[0])\n",
    "print(df_1goalmediation.shape[0])\n",
    "\n",
    "print(df_rag['sequence_boolean'])\n",
    "print(df_norag['sequence_boolean'])\n",
    "\n",
    "print(df_rag['taxonomy_boolean'])\n",
    "print(df_norag['taxonomy_boolean'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a828a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "353\n",
      "177\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#======================\n",
    "#interactive cursor hover\n",
    "#======================\n",
    "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    print(filtered_df.shape[0])\n",
    "\n",
    "    # Step 2: Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sc = ax.scatter(\n",
    "        filtered_df['inclusion_ratio'], \n",
    "        filtered_df['taxonomy_similarity_sbert'], \n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('Inclusion Ratio')\n",
    "    ax.set_ylabel('Taxonomy Similarity')\n",
    "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
    "\n",
    "    # Polynomial fit\n",
    "    N = 1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "    # Limits and layout\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # mplcursors for interactive tooltips\n",
    "    cursor = mplcursors.cursor(sc, hover=True)\n",
    "    \n",
    "    @cursor.connect(\"add\")\n",
    "    def on_add(sel):\n",
    "        idx = sel.index\n",
    "        # Customize the tooltip content here\n",
    "        sel.annotation.set_text(\n",
    "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
    "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
    "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
    "        )\n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
    "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
    "    size1 = df.shape[0]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    print(size1, size2)\n",
    "\n",
    "    # Step 2: Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sc = ax.scatter(\n",
    "        filtered_df['inclusion_ratio'], \n",
    "        filtered_df['sequence_similarity_sbert'], \n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('Inclusion Ratio')\n",
    "    ax.set_ylabel('Sequence Similarity')\n",
    "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
    "\n",
    "    # Polynomial fit\n",
    "    N = 1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "    # Limits and layout\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # mplcursors for interactive tooltips\n",
    "    cursor = mplcursors.cursor(sc, hover=True)\n",
    "    \n",
    "    @cursor.connect(\"add\")\n",
    "    def on_add(sel):\n",
    "        idx = sel.index\n",
    "        # Customize the tooltip content here\n",
    "        sel.annotation.set_text(\n",
    "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
    "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
    "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
    "        )\n",
    " \n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "#======================\n",
    "#non interactive\n",
    "#======================\n",
    "def plot_taxonomy(df):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    # df = df.dropna()\n",
    "    mybool = True\n",
    "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    print(filtered_df.shape[0])\n",
    "    # Step 2: Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
    "    plt.xlabel('Inclusion Ratio')\n",
    "    plt.ylabel('Taxonomy Similarity')\n",
    "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
    "\n",
    "\n",
    "    #Generate smooth x values for curve plotting\n",
    "    N=1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "\n",
    "    plt.xlim(0, 1.1)\n",
    "    plt.ylim(0, 1.1)  \n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_sequence(df):\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    mybool = True\n",
    "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
    "    size2 = filtered_df.shape[0]\n",
    "\n",
    "    # filtered_df = df\n",
    "\n",
    "    # Step 2: Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
    "    plt.xlabel('Inclusion Ratio')\n",
    "    plt.ylabel('Sequence Similarity')\n",
    "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
    "\n",
    "    # Generate smooth x values for curve plotting\n",
    "    N=1\n",
    "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
    "    y_smooth = poly_func(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
    "\n",
    "    plt.xlim(0, 1.1)\n",
    "    plt.ylim(0, 1.1)  \n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "plot_taxonomy_cursor(df_rag, True)\n",
    "plot_taxonomy_cursor(df_rag, False)\n",
    "plot_taxonomy_cursor(df_norag, True)\n",
    "plot_taxonomy_cursor(df_norag, False)\n",
    "# plot_taxonomy_cursor(df_norag)\n",
    "\n",
    "\n",
    "# plot_sequence_cursor(df_rag, True)\n",
    "# plot_sequence_cursor(df_norag, True)\n",
    "# plot_sequence_cursor(df_1direct, False)\n",
    "# plot_sequence_cursor(df_1goalmediation, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a3da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9748f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mplcursors\n",
    "\n",
    "# Dummy DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'inclusion_ratio': np.random.rand(10),\n",
    "    'sequence_similarity_sbert': np.random.rand(10),\n",
    "    'taxonomy_boolean': [True] * 10,\n",
    "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
    "})\n",
    "\n",
    "# plot_sequence_cursor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2e78b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568 555 202 121\n",
      "568 525 177 109\n",
      "44\n",
      "idx\n",
      "idx: 13, 0.75, source_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080, target_uid: 2bc7d6fa-a02e-4367-b316-d6b4e8a2ce3f\n",
      "idx: 28, 0.50, source_uid: 14bcb17c-f70a-41d5-b10d-294388084dfc, target_uid: 2da5c1ee-bd40-406d-83a7-2f3d93293949\n",
      "idx: 34, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 71, 0.35, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 113, 0.50, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 114, 0.40, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 213, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 214, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 229, 0.57, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 230, 0.71, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 266, 0.33, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 269, 0.45, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 303, 1.00, source_uid: 748536e4-636a-4dc6-b1a7-d9cbfdc1cffd, target_uid: abab0e69-f7e4-40c1-aa58-375798df487a\n",
      "idx: 372, 0.78, source_uid: ab7ed4f7-10ee-4ccb-bb21-4853c9018b1e, target_uid: debfb68a-eae2-464e-847a-cd3fea23f3ca\n",
      "idx: 414, 0.75, source_uid: b83285c5-0b88-4ced-a52e-5c34ea371507, target_uid: e72082e8-f9e6-42ac-ac45-de30f9adee9d\n",
      "idx: 479, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 498, 0.29, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "idx: 502, 0.57, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "inclusion_ratio\n",
      "idx: 498, 0.29, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "idx: 266, 0.33, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 71, 0.35, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 114, 0.40, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 34, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 269, 0.45, source_uid: 690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae\n",
      "idx: 113, 0.50, source_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c, target_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4\n",
      "idx: 28, 0.50, source_uid: 14bcb17c-f70a-41d5-b10d-294388084dfc, target_uid: 2da5c1ee-bd40-406d-83a7-2f3d93293949\n",
      "idx: 502, 0.57, source_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5, target_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080\n",
      "idx: 229, 0.57, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 213, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 214, 0.71, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 230, 0.71, source_uid: 56fe0c73-77c4-40d9-a687-b2df28d5f7d7, target_uid: 7e8d03f2-2ff9-431d-af81-e5ffcd954a63\n",
      "idx: 13, 0.75, source_uid: 026dac2d-2ab3-4f9c-9e1d-6198db4fb080, target_uid: 2bc7d6fa-a02e-4367-b316-d6b4e8a2ce3f\n",
      "idx: 414, 0.75, source_uid: b83285c5-0b88-4ced-a52e-5c34ea371507, target_uid: e72082e8-f9e6-42ac-ac45-de30f9adee9d\n",
      "idx: 372, 0.78, source_uid: ab7ed4f7-10ee-4ccb-bb21-4853c9018b1e, target_uid: debfb68a-eae2-464e-847a-cd3fea23f3ca\n",
      "idx: 479, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 303, 1.00, source_uid: 748536e4-636a-4dc6-b1a7-d9cbfdc1cffd, target_uid: abab0e69-f7e4-40c1-aa58-375798df487a\n",
      "idx\n",
      "idx: 36, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 70, 0.31, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 196, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 197, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 210, 0.59, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 261, 0.25, source_uid: 6628a2fb-19e2-4fe5-aedb-92fe5ceee9c9, target_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b\n",
      "idx: 338, 0.67, source_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b, target_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667\n",
      "idx: 347, 0.67, source_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae, target_uid: d7a2e92e-dc74-4e79-be04-a86f829fc3ec\n",
      "idx: 421, 0.46, source_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667, target_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5\n",
      "idx: 476, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 477, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 478, 0.75, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 549, 0.47, source_uid: grp-690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 28e0affc-cacb-4db8-ab32-dfc16931b86a\n",
      "idx: 559, 0.62, source_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585, target_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010\n",
      "inclusion_ratio\n",
      "idx: 261, 0.25, source_uid: 6628a2fb-19e2-4fe5-aedb-92fe5ceee9c9, target_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b\n",
      "idx: 70, 0.31, source_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010, target_uid: 35080724-6604-401c-8b06-19b7cece3d45\n",
      "idx: 36, 0.44, source_uid: 1a894d3c-b3ef-448a-a3de-2b38677cef36, target_uid: 2f46d1e6-2a85-4d46-b955-10c2eded661c\n",
      "idx: 421, 0.46, source_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667, target_uid: ec3556de-be79-4ad4-aa0f-eaca48abb5d5\n",
      "idx: 549, 0.47, source_uid: grp-690f58f1-f18c-4415-bab0-787c2f83d051, target_uid: 28e0affc-cacb-4db8-ab32-dfc16931b86a\n",
      "idx: 210, 0.59, source_uid: 543e4c99-5d9f-407d-be75-c397d633fe56, target_uid: 737e9619-7768-407c-8a4f-6fe1e8d61f04\n",
      "idx: 559, 0.62, source_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585, target_uid: 2978ddbc-cdc9-4bfa-9a7c-4bf056904010\n",
      "idx: 338, 0.67, source_uid: 98434f4c-6216-4067-ad59-4a89cb47bb9b, target_uid: cf95d6a4-6ad7-462c-9700-9f04bd993667\n",
      "idx: 347, 0.67, source_uid: 9fabfbc8-1d5c-495e-9bb2-03795f0145ae, target_uid: d7a2e92e-dc74-4e79-be04-a86f829fc3ec\n",
      "idx: 478, 0.75, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 196, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 197, 0.80, source_uid: 487d752c-6e22-43e3-9c08-627bc2a6c6d4, target_uid: 6ac1d2ed-1f6b-4828-a1ab-f81c40bd5e80\n",
      "idx: 477, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n",
      "idx: 476, 1.00, source_uid: e4ad6fd7-2e3e-4991-b392-a0056f702286, target_uid: grp-b59f7f5d-2991-49a6-8e88-0e2f2db92585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_taxdf(df:dict):\n",
    "    size0 = df.shape[0]\n",
    "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
    "    size1 = df.shape[0]\n",
    "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
    "    size2 = filtered_df.shape[0]\n",
    "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
    "    size3 = filtered_df.shape[0]\n",
    "\n",
    "    print(f\"{size0} {size1} {size2} {size3}\")\n",
    "    return filtered_df\n",
    "\n",
    "filtered_df_rag = filter_taxdf(df_rag)\n",
    "filtered_df_norag = filter_taxdf(df_norag)\n",
    "\n",
    "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
    "    filtered_df = df[df[sbertitem] > min]\n",
    "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
    "    size = filtered_df.shape[0]\n",
    "    # print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
    "    print(\"idx\")\n",
    "    filtered_df = filtered_df.sort_values(by='idx')\n",
    "    for i in range(size):\n",
    "        print(f\"idx: {filtered_df.iloc[i]['idx']}, {filtered_df.iloc[i]['inclusion_ratio']:.2f}, source_uid: {filtered_df.iloc[i]['source_uid']}, target_uid: {filtered_df.iloc[i]['target_uid']}\")\n",
    "\n",
    "    print(\"inclusion_ratio\")\n",
    "    filtered_df = filtered_df.sort_values(by='inclusion_ratio')\n",
    "    for i in range(size):\n",
    "        print(f\"idx: {filtered_df.iloc[i]['idx']}, {filtered_df.iloc[i]['inclusion_ratio']:.2f}, source_uid: {filtered_df.iloc[i]['source_uid']}, target_uid: {filtered_df.iloc[i]['target_uid']}\")\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
    "    '''\n",
    "    k:keyname\n",
    "    '''\n",
    "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
    "\n",
    "\n",
    "\n",
    "# find passed true rags and lookat same index\n",
    "common_idx = set(filtered_df_rag['idx']) & set(filtered_df_norag['idx'])\n",
    "df_common = filtered_df_rag[filtered_df_rag['idx'].isin(common_idx)]\n",
    "print(df_common.shape[0])\n",
    "df_common1 = filter_by_sbert(df_common, 'taxonomy_similarity_sbert', 0.95, 1.0)\n",
    "df_common2 = filter_by_sbert(df_common, 'taxonomy_similarity_sbert', 0.90, 0.95)\n",
    "\n",
    "\n",
    "# # for 1.0 both seq and taxonomy survives\n",
    "# print(\"sbert 1.0\")\n",
    "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.95, 1.0)\n",
    "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
    "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.95,1.0)\n",
    "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.95,1.0)\n",
    "\n",
    "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
    "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
    "# more_common_list1 = list(set(common_rag) & set(common_norag))\n",
    "# print(f\"{len(common_rag)} {common_rag}\")\n",
    "# print(f\"{len(common_norag)} {common_norag}\")\n",
    "# print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
    "\n",
    "# print(\"sbert 0.65-0.75\")\n",
    "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
    "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
    "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
    "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
    "\n",
    "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
    "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
    "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
    "# print(f\"{len(common_rag)} {common_rag}\")\n",
    "# print(f\"{len(common_norag)} {common_norag}\")\n",
    "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
    "\n",
    "# print(\"sbert 0.5-0.5\")\n",
    "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
    "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
    "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
    "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
    "\n",
    "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
    "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
    "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
    "# print(f\"{len(common_rag)} {common_rag}\")\n",
    "# print(f\"{len(common_norag)} {common_norag}\")\n",
    "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
    "# # find uid that made through both booleans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bd40cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%matplotlib qt\n",
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "import json\n",
      "import torch\n",
      "import matplotlib.pyplot as plt\n",
      "import mplcursors\n",
      "from sklearn.manifold import TSNE\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "\n",
      "import pickle\n",
      "\n",
      "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
      "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
      "from util import util_constants\n",
      "from util import util_funcs\n",
      "import f4_evaluate.evaluate_scene as evaluate_scene\n",
      "import f1_init.database_init as database_init\n",
      "import f1_init.agent_init as agent_init\n",
      "import f1_init.constants_init as constants_init\n",
      "\n",
      "#Computing similarity\n",
      "import json\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "import numpy as np\n",
      "from numpy.linalg import norm\n",
      "import ast\n",
      "import pandas as pd\n",
      "\n",
      "#PATHS\n",
      "PATH_CURR_FOLDER = os.path.abspath('') \n",
      "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
      "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
      "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
      "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
      "\n",
      "#PAIRSIM DATA\n",
      "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
      "\n",
      "#AUGMENTED DATA PATH\n",
      "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
      "TEST_SPATIAL_ANNOTATION_V2_PATH = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_v2/'\n",
      "\n",
      "#BASELINE RESULT PATHS\n",
      "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag/'))\n",
      "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag/'))\n",
      "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1direct/'))\n",
      "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1goalmediation/'))\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 * 8 #8levels, 8files\n",
      "\n",
      "    # for i in range(length):\n",
      "    for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "        dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "        dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "        dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "\n",
      "\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(len(baseline_norag_list))\n",
      "print(len(baseline_rag_list))\n",
      "\n",
      "print(len(baseline_1direct_list))\n",
      "print(len(baseline_1goalmediation_list))\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df(df_norag)\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df(df_norag)\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "%matplotlib notebook\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "plot_sequence_cursor(df)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "plot_sequence(df_1direct)\n",
      "plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    df = df.dropna()\n",
      "    mybool = False\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "plot_sequence(df_1direct)\n",
      "plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "plot_sequence(df_1direct)\n",
      "plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    # N=1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "        dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "        dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "        dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(len(baseline_rag_list))\n",
      "print(len(baseline_norag_list))\n",
      "print(len(baseline_1direct_list))\n",
      "print(len(baseline_1goalmediation_list))\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "        dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "        dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "        dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(len(baseline_rag_list))\n",
      "print(len(baseline_norag_list))\n",
      "print(len(baseline_1direct_list))\n",
      "print(len(baseline_1goalmediation_list))\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "# plot_sequence(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence(df_rag)\n",
      "# plot_sequence(df_norag)\n",
      "# plot_sequence(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # print(df.head())\n",
      "    # df = df[df['taxonomy_boolean'] == True]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "%matplotlib qt\n",
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "import json\n",
      "import torch\n",
      "import matplotlib.pyplot as plt\n",
      "import mplcursors\n",
      "from sklearn.manifold import TSNE\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "\n",
      "import pickle\n",
      "\n",
      "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
      "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
      "from util import util_constants\n",
      "from util import util_funcs\n",
      "import f4_evaluate.evaluate_scene as evaluate_scene\n",
      "import f1_init.database_init as database_init\n",
      "import f1_init.agent_init as agent_init\n",
      "import f1_init.constants_init as constants_init\n",
      "\n",
      "#Computing similarity\n",
      "import json\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from bert_score import score\n",
      "import numpy as np\n",
      "from numpy.linalg import norm\n",
      "import ast\n",
      "import pandas as pd\n",
      "\n",
      "#PATHS\n",
      "PATH_CURR_FOLDER = os.path.abspath('') \n",
      "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
      "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
      "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
      "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
      "\n",
      "#PAIRSIM DATA\n",
      "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
      "\n",
      "#AUGMENTED DATA PATH\n",
      "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
      "TEST_SPATIAL_ANNOTATION_V2_PATH = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_v2/'\n",
      "\n",
      "#BASELINE RESULT PATHS\n",
      "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag/'))\n",
      "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag/'))\n",
      "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1direct/'))\n",
      "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1goalmediation/'))\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            # dict[\"sequence_boolean\"] = False\n",
      "            # dict[\"taxonomy_boolean\"] = False \n",
      "            continue\n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            # print(values[1])\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # # Polynomial fit\n",
      "    # N = 1\n",
      "    # coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    # poly_func = np.poly1d(coeffs)\n",
      "    # x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    # y_smooth = poly_func(x_smooth)\n",
      "    # ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['sequence_boolean'])\n",
      "print(df_norag['sequence_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['sequence_boolean'])\n",
      "print(df_norag['sequence_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "print(df_rag['sequence_boolean'])\n",
      "print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(dict[\"sequence_boolean\"])\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict[\"taxonomy_boolean\"]} {dict[\"sequence_boolean\"]}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict[\"taxonomy_boolean\"]} {dict[\"sequence_boolean\"]}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Pairwise Similarity')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'2Pairwise vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Pairwise Similarity')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Pairwise vs. Taxonomy Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "\n",
      "        # CALCULATE SIMILARITY DATA (SBERT, BERTSCORE)\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "    print(source_tax)\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "    print(entry.get('source_taxnomy'))\n",
      "    print(source_tax)\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "    print(entry.get('source_taxnomy'))\n",
      "    print(source_tax)\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "\n",
      "    print(target_tax)\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            print(dict['source_taxonomy'])\n",
      "            print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "def load_file(path):\n",
      "    try:          \n",
      "         with open(path, \"rb\") as f:\n",
      "             data = pickle.load(f)\n",
      "             return data\n",
      "    except:\n",
      "         return None\n",
      "    \n",
      "#=====================================\n",
      "# SIMILARITIES\n",
      "#=====================================\n",
      "def cosine_similarity(vec1, vec2):\n",
      "    vec1 = np.array(vec1)\n",
      "    vec2 = np.array(vec2)\n",
      "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
      "        return 0.0\n",
      "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
      "\n",
      "def safe_parse_sequence(seq):\n",
      "    if seq is None:\n",
      "        return []\n",
      "    if isinstance(seq, list):\n",
      "        return seq\n",
      "    try:\n",
      "        return ast.literal_eval(seq)\n",
      "    except (ValueError, SyntaxError):\n",
      "        print(\"taxonomy safe parse value error\")\n",
      "        return []\n",
      "\n",
      "def safe_parse_taxonomy(tax):\n",
      "    if tax is None:\n",
      "        return {}\n",
      "    if isinstance(tax, dict):\n",
      "        return tax\n",
      "    try:\n",
      "        return json.loads(tax)\n",
      "    except (json.JSONDecodeError, TypeError):\n",
      "        return {}\n",
      "\n",
      "def compute_similarities(entry, embed_model):\n",
      "    # --- Parse sequences ---\n",
      "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
      "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
      "\n",
      "    if not source_seq or not target_seq:\n",
      "        seq_similarity = 0.0\n",
      "    else:\n",
      "        source_seq_str = ' '.join(source_seq)\n",
      "        target_seq_str = ' '.join(target_seq)\n",
      "        source_seq_emb = embed_model.encode(source_seq_str)\n",
      "        target_seq_emb = embed_model.encode(target_seq_str)\n",
      "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
      "\n",
      "    # --- Parse taxonomies ---\n",
      "    source_tax = safe_parse_taxonomy(entry.get('source_taxonomy'))\n",
      "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
      "\n",
      "    if not source_tax or not target_tax:\n",
      "        tax_similarity = 0.0\n",
      "    else:\n",
      "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
      "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
      "        source_tax_emb = embed_model.encode(source_tax_str)\n",
      "        target_tax_emb = embed_model.encode(target_tax_str)\n",
      "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
      "\n",
      "    return seq_similarity, tax_similarity\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "# baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "# baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "# baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "# plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "plot_taxonomy(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
      "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
      "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
      "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "\n",
      "\n",
      "def make_singlebaseline_list(baseline_result_path:str, baseline:str):\n",
      "    '''\n",
      "    func: make single baseline list\n",
      "\n",
      "    '''\n",
      "    baseline_result_path = baseline_result_path + \"/\"\n",
      "    baseline_results = []\n",
      "    augmodes = [30, 40, 50, 60, 70, 80, 90, 100]\n",
      "    length = 71 * 8 #8levels, 8files\n",
      "\n",
      "    for i in range(length):\n",
      "    # for i in range(568):\n",
      "        # print(i)\n",
      "        dict = {\n",
      "            \"source_idx\":None, \"target_idx\":None, \"source_uid\": None, \"baseline\": None, \"augmode\": None, \n",
      "            \"source_sequence\": None, \"source_scene_graph\": None, \"target_scene_graph\": None, \n",
      "            # \"core_activity\": None, \"source_taxonomy\": None, \"common_taxonomy\": None, \n",
      "            # \"target_taxonomy\": None, \"target_sequence\": None, \n",
      "            # \"sequence_boolean\": None, \"taxonomy_boolean\": None, \n",
      "            \"inclusion_ratio\":None, #\"pairwise_similarity\": None,\n",
      "            #\"sequence_similarity_sbert\": None, \"taxonomy_similarity_sbert\":None\n",
      "            }\n",
      "\n",
      "        prefix = f\"pair{i}_\"\n",
      "        augmode = i%len(augmodes)\n",
      "        # FILL RAW DATA\n",
      "        sourceinfo_dict = load_file(baseline_result_path + prefix + \"sourceinfo.pkl\")\n",
      "        targetinfo_dict = load_file(baseline_result_path + prefix + \"targetinfo.pkl\")\n",
      "        dict[\"source_idx\"] = sourceinfo_dict['source_idx']\n",
      "        dict[\"target_idx\"] = targetinfo_dict['target_idx']\n",
      "        dict[\"source_uid\"] = sourceinfo_dict['source_uid']\n",
      "        dict[\"baseline\"] = baseline\n",
      "        dict[\"augmode\"] = augmode\n",
      "\n",
      "\n",
      "        dict['source_sequence'] =sourceinfo_dict['source_action_sequence']\n",
      "        dict['source_sequence'] = dict['source_sequence'].strip('\"').split(', ') #make into list\n",
      "\n",
      "        dict['source_scene_graph'] =sourceinfo_dict['source_scene_graph']\n",
      "        dict['target_scene_graph'] =targetinfo_dict['target_scene_graph']\n",
      "\n",
      "        \n",
      "        # based on baselines     \n",
      "        if baseline == \"1direct\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "        if baseline == \"1goalmediation\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "        elif baseline == \"rag\" or baseline ==\"norag\":\n",
      "            dict['target_sequence'] =load_file(baseline_result_path + prefix + \"agent3.pkl\")\n",
      "            dict['core_activity'] =load_file(baseline_result_path + prefix + \"agent1a.pkl\")\n",
      "            dict['source_taxonomy'] =load_file(baseline_result_path + prefix + \"agent1b.pkl\")\n",
      "            dict['common_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2a.pkl\")\n",
      "            dict['target_taxonomy'] =load_file(baseline_result_path + prefix + \"agent2b.pkl\")\n",
      "\n",
      "\n",
      "        booleans= load_file(baseline_result_path+prefix+\"agent4.pkl\")\n",
      "        if(booleans == None):\n",
      "            ## No values whatsover\n",
      "            dict[\"sequence_boolean\"] = False\n",
      "            dict[\"taxonomy_boolean\"] = False \n",
      "        else:\n",
      "            values = [\n",
      "                line.split(\":\")[1].strip()\n",
      "                for line in booleans.strip().splitlines()\n",
      "                if \":\" in line\n",
      "            ]\n",
      "            print(values)\n",
      "            dict[\"taxonomy_boolean\"] = True if values[0] == 'yes' else False\n",
      "            dict[\"sequence_boolean\"] = True if values[1] == 'yes' else False\n",
      "            # print(f\"{dict['taxonomy_boolean']} {dict['sequence_boolean']}\")\n",
      "        \n",
      "        dict['inclusion_ratio'] = sourceinfo_dict['spatial_similarity']\n",
      "        #dict['pairwise_similarity'] = compare_scene_graph(dict['source_scene_graph'], dict['target_scene_graph'])\n",
      "        # SBERT for block level semantics\n",
      "\n",
      "        if dict['target_sequence'] != None:\n",
      "            \n",
      "            # Preprocess sequece to make sequence a single string\n",
      "            dict['target_sequence'] = ast.literal_eval(dict['target_sequence'])\n",
      "            dict['target_sequence'] = [\", \".join(dict['target_sequence'])] # to single item\n",
      "            dict['source_sequence'] = [\", \".join(dict['source_sequence'])]# to single item\n",
      "            \n",
      "            # print(dict['source_taxonomy'])\n",
      "            # print(dict['target_taxonomy'])\n",
      "\n",
      "            sequence_similarity_sbert, taxonomy_similarity_sbert = compute_similarities(dict, sbert_model)\n",
      "            dict[\"sequence_similarity_sbert\"]= sequence_similarity_sbert\n",
      "            dict[\"taxonomy_similarity_sbert\"]= taxonomy_similarity_sbert\n",
      "            print(dict[\"taxonomy_similarity_sbert\"])\n",
      "\n",
      "            # BERTSCORE for little more stepwise precision in similarity measurement\n",
      "            # print(len(dict['target_sequence']))\n",
      "            # print(len(dict['source_sequence']))\n",
      "            # print(dict['target_sequence'])\n",
      "            # print(dict['source_sequence'])# not inside bracket\n",
      "            # print(dict['target_taxonomy'])\n",
      "            # print(dict['source_taxonomy'])\n",
      "\n",
      "            #takes very long\n",
      "            # dict[\"sequence_b_P\"], dict[\"sequence_b_R\"], dict[\"sequence_b_F1\"] = score(dict['target_sequence'], dict['source_sequence'], lang=\"en\", rescale_with_baseline=True)\n",
      "\n",
      "            #This part gives trouble\n",
      "            # dict[\"taxonomy_b_P\"], dict[\"taxonomy_b_R\"], dict[\"taxonomy_b_F1\"] =score(dict['target_taxonomy'], dict['source_taxonomy'], lang=\"en\", rescale_with_baseline=True)\n",
      "        baseline_results.append(dict)\n",
      "    return baseline_results\n",
      "\n",
      "baseline_rag_list = make_singlebaseline_list(PATH_BASELINE_RAG, baselines[0])\n",
      "baseline_norag_list = make_singlebaseline_list(PATH_BASELINE_NORAG, baselines[1])\n",
      "baseline_1direct_list = make_singlebaseline_list(PATH_BASELINE_1DIRECT, baselines[2])\n",
      "baseline_1goalmediation_list = make_singlebaseline_list(PATH_BASELINE_1GOALMEDIATION, baselines[3])\n",
      "\n",
      "# print(f\"{len(baseline_rag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_norag_list)} {len(baseline_norag_list[0])}\")\n",
      "# print(f\"{len(baseline_1direct_list)} {len(baseline_1direct_list[0])}\")\n",
      "# print(f\"{len(baseline_1goalmediation_list)} {len(baseline_1goalmediation_list[0])}\")\n",
      "\n",
      "def mask_nan_df(df):\n",
      "    mask = df.isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan \n",
      "    \n",
      "def mask_nan_df_or_condition(df, columns_to_check):\n",
      "    '''\n",
      "    input: columns_to_check = [\"col1\", \"col2\"]\n",
      "    '''\n",
      "    mask = df[columns_to_check].isna().any(axis=1)\n",
      "    df.loc[mask, :] = np.nan    \n",
      "\n",
      "def save_baseline_list(path, baseline_list):\n",
      "    with open(path, 'wb') as f:\n",
      "        pickle.dump(baseline_list, f)\n",
      "        print(f\"saved baseline list at {path}\")\n",
      "\n",
      "# turn list of dictionary into dataframe\n",
      "# df_rag = pd.DataFrame(baseline_rag_list)\n",
      "\n",
      "\n",
      "df_rag = pd.DataFrame(baseline_rag_list)\n",
      "# mask_nan_df_or_condition(df_rag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_norag = pd.DataFrame(baseline_norag_list)\n",
      "# mask_nan_df_or_condition(df_norag, [\"target_taxonomy\",\"target_sequence\"])\n",
      "\n",
      "df_1direct = pd.DataFrame(baseline_1direct_list)\n",
      "mask_nan_df_or_condition(df_1direct, [\"target_sequence\"])\n",
      "# print(df_1direct.head())\n",
      "\n",
      "df_1goalmediation = pd.DataFrame(baseline_1goalmediation_list)\n",
      "mask_nan_df_or_condition(df_1goalmediation, [\"target_sequence\"])\n",
      "# print(df_1goalmediation.head())\n",
      "\n",
      "\n",
      "baseline_rag_path = 'evaluation_result_v4/rag_dict.pkl'\n",
      "baseline_norag_path = 'evaluation_result_v4/norag_dict.pkl'\n",
      "baseline_1direct_path = 'evaluation_result_v4/1direct_dict.pkl'\n",
      "baseline_1goalmediation_list_path = 'evaluation_result_v4/1goalmediation_dict.pkl'\n",
      "\n",
      "save_baseline_list(baseline_rag_path, baseline_rag_list)\n",
      "save_baseline_list(baseline_norag_path, baseline_norag_list)\n",
      "save_baseline_list(baseline_1direct_path, baseline_1direct_list)\n",
      "save_baseline_list(baseline_1goalmediation_list_path, baseline_1goalmediation_list)\n",
      "\n",
      "\n",
      "print(df_rag.shape[0])\n",
      "print(df_norag.shape[0])\n",
      "print(df_1direct.shape[0])\n",
      "print(df_1goalmediation.shape[0])\n",
      "\n",
      "# print(df_rag['sequence_boolean'])\n",
      "# print(df_norag['sequence_boolean'])\n",
      "\n",
      "print(df_rag['taxonomy_boolean'])\n",
      "print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag)\n",
      "plot_taxonomy_cursor(df_norag)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag, True)\n",
      "plot_taxonomy_cursor(df_rag, False)\n",
      "plot_taxonomy_cursor(df_norag, True)\n",
      "plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag)\n",
      "# plot_sequence_cursor(df_norag)\n",
      "# plot_sequence_cursor(df_1direct)\n",
      "# plot_sequence_cursor(df_1goalmediation)\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "# plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag)\n",
      "plot_sequence_cursor(df_norag)\n",
      "plot_sequence_cursor(df_1direct)\n",
      "plot_sequence_cursor(df_1goalmediation)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "%matplotlib qt\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import mplcursors\n",
      "\n",
      "# Dummy DataFrame\n",
      "df = pd.DataFrame({\n",
      "    'inclusion_ratio': np.random.rand(10),\n",
      "    'sequence_similarity_sbert': np.random.rand(10),\n",
      "    'taxonomy_boolean': [True] * 10,\n",
      "    'source_uid': [f\"Item {i}\" for i in range(40, 50)]\n",
      "})\n",
      "\n",
      "# plot_sequence_cursor(df)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Assume df is your DataFrame\n",
      "\n",
      "# Step 1: Filter where taxonomy_boolean is True\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "print(df_1direct['sequence_boolean'])\n",
      "print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "# print(df_rag['taxonomy_boolean'])\n",
      "# print(df_norag['taxonomy_boolean'])\n",
      "print(df_1direct['sequence_similarity_sbert'])\n",
      "print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "# print(df_rag['taxonomy_boolean'])\n",
      "# print(df_norag['taxonomy_boolean'])\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    # df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, True)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "print(df_1direct['sequence_similarity_sbert'])\n",
      "print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "print(df_1direct['sequence_boolean'])\n",
      "print(df_1goalmediation['sequence_boolean'])\n",
      "# print(df_rag['taxonomy_boolean'])\n",
      "# print(df_norag['taxonomy_boolean'])\n",
      "print(df_1direct['sequence_similarity_sbert'])\n",
      "print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "print(df_1direct['sequence_boolean'])\n",
      "print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "df_1direct_bool = df_1direct[df_1direct['sequence_boolean'] == True]\n",
      "print(df_1direct)\n",
      "# print(df_1direct['sequence_similarity_sbert'])\n",
      "# print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "# print(df_1direct['sequence_boolean'])\n",
      "# print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "df_1direct_bool = df_1direct[df_1direct['sequence_boolean'] == True]\n",
      "print(df_1direct)\n",
      "# print(df_1direct['sequence_similarity_sbert'])\n",
      "# print(df_1goalmediation['sequence_similarity_sbert'])\n",
      "\n",
      "# print(df_1direct['sequence_boolean'])\n",
      "# print(df_1goalmediation['sequence_boolean'])\n",
      "\n",
      "df_1direct_bool = df_1direct[df_1direct['sequence_boolean'] == True]\n",
      "print(df_1direct)\n",
      "\n",
      "df_1goalmediation_bool = df_1goalmediation[df_1goalmediation['sequence_boolean'] == True]\n",
      "print(df_1goalmediation_bool)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, False)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "# plot_taxonomy_cursor(df_rag, True)\n",
      "# plot_taxonomy_cursor(df_rag, False)\n",
      "# plot_taxonomy_cursor(df_norag, True)\n",
      "# plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "plot_sequence_cursor(df_rag, True)\n",
      "plot_sequence_cursor(df_norag, True)\n",
      "plot_sequence_cursor(df_1direct, False)\n",
      "plot_sequence_cursor(df_1goalmediation, True)\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag, True)\n",
      "plot_taxonomy_cursor(df_rag, False)\n",
      "plot_taxonomy_cursor(df_norag, True)\n",
      "plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "# plot_sequence_cursor(df_1direct, False)\n",
      "# plot_sequence_cursor(df_1goalmediation, True)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', sequence_boolean])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size4 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size4 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    print(filtered_df['source_uid'])\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(filtered_df['source_uid'])\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, max:float, min:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.85)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.65,0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.7)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.5)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_siimlarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_siimlarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_siimlarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_siimlarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_siimlarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_siimlarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_simlarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_simlarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_simlarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_simlarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_simlarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_simlarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(size)\n",
      "    print(list(filtered_df['source_uid']))\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "# print(\"sbert 1.0\")\n",
      "# # filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# # filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "# # filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "# # filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def filter_common_uid(dict1:dict, dict2:dict):\n",
      "    common_dict = {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "    size = common_dict.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return common_dict\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "common_df_rag_tax = filter_common_uid(filtered_df_rag_tax, filtered_df_rag_seq )\n",
      "common_df_rag_tax = filter_common_uid(filtered_df_norag_tax, filtered_df_norag_seq )\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(common_rag)\n",
      "print(common_norag)\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.95,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.7, 0.75)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] >= min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8, 0.899)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8, 0.899)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8, 0.899)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8, 0.899)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.5,0.55)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list)} {more_common_list}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "print(\"sbert 0.65-0.75\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "print(\"sbert 0.5-0.5\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str)\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.90,1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str)\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "\n",
      "common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    # print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.9,1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "# find uid that made through both booleans\n",
      "\n",
      "def filter_taxdf(df:dict):\n",
      "    size0 = df.shape[0]\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
      "    size3 = filtered_df.shape[0]\n",
      "\n",
      "    print(f\"{size0} {size1} {size2} {size3}\")\n",
      "    return filtered_df\n",
      "\n",
      "filtered_df_rag = filter_taxdf(df_rag)\n",
      "filtered_df_norag = filter_taxdf(df_norag)\n",
      "\n",
      "def filter_by_sbert(df:dict, sbertitem:str, min:float, max:float):\n",
      "    filtered_df = df[df[sbertitem] > min]\n",
      "    filtered_df = filtered_df[filtered_df[sbertitem] <= max]\n",
      "    size = filtered_df.shape[0]\n",
      "    # print(f\"{size} : {list(filtered_df['source_uid'])}\")\n",
      "    return filtered_df\n",
      "\n",
      "def get_common_dict(dict1:dict, dict2:dict, k:str):\n",
      "    '''\n",
      "    k:keyname\n",
      "    '''\n",
      "    return {k: dict1[k] for k in dict1 if k in dict2 and dict1[k] == dict2[k]}\n",
      "\n",
      "\n",
      "\n",
      "# find uid with certain sbert value\n",
      "# for 1.0 both seq and taxonomy survives\n",
      "print(\"sbert 1.0\")\n",
      "filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 1.0,1.0)\n",
      "\n",
      "# common_rag = get_common_dict(filtered_df_rag_tax, filtered_df_norag_tax, 'source_uid')\n",
      "# common_norag = get_common_dict(filtered_df_norag_tax, filtered_df_norag_seq, 'source_uid')\n",
      "# common_all = get_common_dict(common_rag, common_norag, 'source_uid')\n",
      "# print(f\"{common_all['source_uid']}\")\n",
      "\n",
      "\n",
      "common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "more_common_list1 = list(set(common_rag) & set(common_norag))\n",
      "print(f\"{len(common_rag)} {common_rag}\")\n",
      "print(f\"{len(common_norag)} {common_norag}\")\n",
      "print(f\"{len(more_common_list1)} {more_common_list1}\")\n",
      "\n",
      "# print(\"sbert 0.65-0.75\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.85, 0.9)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list2 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list2)} {more_common_list2}\")\n",
      "\n",
      "# print(\"sbert 0.5-0.5\")\n",
      "# filtered_df_rag_tax = filter_by_sbert(df_rag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_tax = filter_by_sbert(df_norag, 'taxonomy_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_rag_seq = filter_by_sbert(df_rag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "# filtered_df_norag_seq = filter_by_sbert(df_norag, 'sequence_similarity_sbert', 0.8,0.85)\n",
      "\n",
      "# common_rag = list(set(list(filtered_df_rag_tax['source_uid'])) & set(list(filtered_df_rag_seq['source_uid'])))\n",
      "# common_norag = list(set(list(filtered_df_norag_tax['source_uid'])) & set(list(filtered_df_norag_seq['source_uid'])))\n",
      "# more_common_list3 = list(set(common_rag) & set(common_norag))\n",
      "# print(f\"{len(common_rag)} {common_rag}\")\n",
      "# print(f\"{len(common_norag)} {common_norag}\")\n",
      "# print(f\"{len(more_common_list3)} {more_common_list3}\")\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#======================\n",
      "#interactive cursor hover\n",
      "#======================\n",
      "def plot_taxonomy_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['taxonomy_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Taxonomy Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['taxonomy_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "def plot_sequence_cursor(df:pd.DataFrame, mybool:bool):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size1 = df.shape[0]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(size1, size2)\n",
      "\n",
      "    # Step 2: Plot\n",
      "    fig, ax = plt.subplots(figsize=(8, 6))\n",
      "    sc = ax.scatter(\n",
      "        filtered_df['inclusion_ratio'], \n",
      "        filtered_df['sequence_similarity_sbert'], \n",
      "        alpha=0.7\n",
      "    )\n",
      "\n",
      "    ax.set_xlabel('Inclusion Ratio')\n",
      "    ax.set_ylabel('Sequence Similarity')\n",
      "    ax.set_title(f'Inclusion Ratio vs. Sequence Similarity (bool={mybool}) {size2}/{size1}')\n",
      "\n",
      "    # Polynomial fit\n",
      "    N = 1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    ax.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    # Limits and layout\n",
      "    ax.set_xlim(0, 1.1)\n",
      "    ax.set_ylim(0, 1.1)\n",
      "    ax.grid(True)\n",
      "    plt.tight_layout()\n",
      "\n",
      "    # mplcursors for interactive tooltips\n",
      "    cursor = mplcursors.cursor(sc, hover=True)\n",
      "    \n",
      "    @cursor.connect(\"add\")\n",
      "    def on_add(sel):\n",
      "        idx = sel.index\n",
      "        # Customize the tooltip content here\n",
      "        sel.annotation.set_text(\n",
      "            f\"x: {filtered_df['inclusion_ratio'].iloc[idx]:.2f}\\n\"\n",
      "            f\"y: {filtered_df['sequence_similarity_sbert'].iloc[idx]:.2f}\\n\"\n",
      "            f\"info: {filtered_df.get('source_uid', pd.Series(['N/A'] * size2)).iloc[idx]}\"\n",
      "        )\n",
      " \n",
      "\n",
      "    plt.show()    \n",
      "\n",
      "#======================\n",
      "#non interactive\n",
      "#======================\n",
      "def plot_taxonomy(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'taxonomy_similarity_sbert', 'taxonomy_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    # df = df.dropna()\n",
      "    mybool = True\n",
      "    filtered_df = df[df['taxonomy_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "    print(filtered_df.shape[0])\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Taxonomy Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Taxonomy Similarity (Only where taxonomy_boolean={mybool}) {size2}/{size1}')\n",
      "\n",
      "\n",
      "    #Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['taxonomy_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "def plot_sequence(df):\n",
      "    df = df.dropna(subset=['inclusion_ratio', 'sequence_similarity_sbert', 'sequence_boolean'])\n",
      "    size1 = df.shape[0]\n",
      "    mybool = True\n",
      "    filtered_df = df[df['sequence_boolean'] == mybool]\n",
      "    size2 = filtered_df.shape[0]\n",
      "\n",
      "    # filtered_df = df\n",
      "\n",
      "    # Step 2: Plot\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.scatter(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], alpha=0.7)\n",
      "    plt.xlabel('Inclusion Ratio')\n",
      "    plt.ylabel('Sequence Similarity')\n",
      "    plt.title(f'Inclusion Ratio vs. Sequence Similarity (Only where sequence_boolean={mybool} {size2}/{size1})')\n",
      "\n",
      "    # Generate smooth x values for curve plotting\n",
      "    N=1\n",
      "    coeffs = np.polyfit(filtered_df['inclusion_ratio'], filtered_df['sequence_similarity_sbert'], deg=N)\n",
      "    poly_func = np.poly1d(coeffs)\n",
      "    x_smooth = np.linspace(filtered_df['inclusion_ratio'].min(), filtered_df['inclusion_ratio'].max(), 200)\n",
      "    y_smooth = poly_func(x_smooth)\n",
      "    plt.plot(x_smooth, y_smooth, color='red', label=f'{N}° polynomial fit')\n",
      "\n",
      "    plt.xlim(0, 1.1)\n",
      "    plt.ylim(0, 1.1)  \n",
      "\n",
      "    plt.grid(True)\n",
      "    plt.tight_layout()\n",
      "    plt.show()    \n",
      "\n",
      "\n",
      "plot_taxonomy_cursor(df_rag, True)\n",
      "plot_taxonomy_cursor(df_rag, False)\n",
      "plot_taxonomy_cursor(df_norag, True)\n",
      "plot_taxonomy_cursor(df_norag, False)\n",
      "# plot_taxonomy_cursor(df_norag)\n",
      "\n",
      "\n",
      "# plot_sequence_cursor(df_rag, True)\n",
      "# plot_sequence_cursor(df_norag, True)\n",
      "# plot_sequence_cursor(df_1direct, False)\n",
      "# plot_sequence_cursor(df_1goalmediation, True)\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b91924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
