{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325a1267",
   "metadata": {},
   "source": [
    "# Evaluate Plots\n",
    "\n",
    "test pair에 대한 iteration을 수행한다.\n",
    "\n",
    "1. pickle을 통해서 모든 아이템을 다 읽는다.\n",
    "2. 현재 source sequence를 읽는다.\n",
    "3. scene similarity를 읽는다.\n",
    "\n",
    "4. action sequence similarity를 계산한다.\n",
    "5. activity taxnomy similarity를 계산한다.\n",
    "\n",
    "\n",
    "다음의 pandas colum을 구성한다. (284x10 정도 되나?)\n",
    "\n",
    "없는 곳은 None표시를 한다.\n",
    "\n",
    "source idx, target idx, \n",
    "augmentation_id, scene similarity\n",
    "core activity_gt, core activity_inf\n",
    "sequence sim, taxonomy sim\n",
    "sequence bool, taxonomy bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath('/root/project')) # add root path to sys.path\n",
    "sys.path.append(os.path.abspath('/usr/local/lib/python3.10/dist-packages'))\n",
    "from util import util_constants\n",
    "from util import util_funcs\n",
    "import f4_evaluate.evaluate_scene as evaluate_scene\n",
    "import f1_init.database_init as database_init\n",
    "import f1_init.agent_init as agent_init\n",
    "import f1_init.constants_init as constants_init\n",
    "\n",
    "#Computing similarity\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "#PATHS\n",
    "PATH_CURR_FOLDER = os.path.abspath('') \n",
    "PATH_DATA_ANNOTATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_annotation'))\n",
    "PATH_DATA_INPUT_OUTPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output'))\n",
    "PATH_SOURCE_TARGET_INPUT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/input/source_target_video_list.pkl'))\n",
    "TEST_SPATIAL_ANNOTATION_PATH_MANUAL = PATH_DATA_ANNOTATION + '/spatial_testset/manual'\n",
    "\n",
    "#PAIRSIM DATA\n",
    "PATH_PAIRSIM = PATH_DATA_ANNOTATION + '/spatial_pairsim_result'\n",
    "\n",
    "#AUGMENTED DATA PATH\n",
    "TEST_SPATIAL_ANNOTATION_PATH_SEMI = PATH_DATA_ANNOTATION + '/spatial_testset/semi'    \n",
    "TEST_SPATIAL_ANNOTATION_PATH_AUG100 = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_100_v3' \n",
    "TEST_SPATIAL_ANNOTATION_PATH_AUG67 = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_67_v3' \n",
    "TEST_SPATIAL_ANNOTATION_PATH_AUG33 = PATH_DATA_ANNOTATION + '/spatial_augmentation/TESTSET_Augmented_Data_33_v3' \n",
    "\n",
    "#BASELINE RESULT PATHS\n",
    "PATH_BASELINE_RAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-rag-0520'))\n",
    "PATH_BASELINE_NORAG = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-norag-0520'))\n",
    "PATH_BASELINE_1DIRECT = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1-direct-0520'))\n",
    "PATH_BASELINE_1GOALMEDIATION = os.path.abspath(os.path.join(PATH_CURR_FOLDER, '..', 'data_input_output/output-1-goalmediation-0520'))\n",
    "\n",
    "# PREPROCESS VIDEO_LISTS for TEST DATA & SORT\n",
    "test_spatial_video_list = database_init.make_spatial_json_video_list(TEST_SPATIAL_ANNOTATION_PATH_MANUAL, TEST_SPATIAL_ANNOTATION_PATH_SEMI)\n",
    "test_spatial_video_aug100_list = database_init.make_spatial_json_video_list_singlepath(TEST_SPATIAL_ANNOTATION_PATH_AUG100)\n",
    "test_spatial_video_aug67_list = database_init.make_spatial_json_video_list_singlepath(TEST_SPATIAL_ANNOTATION_PATH_AUG67)\n",
    "test_spatial_video_aug33_list = database_init.make_spatial_json_video_list_singlepath(TEST_SPATIAL_ANNOTATION_PATH_AUG33)\n",
    "#Sort test_spatial_video_list first\n",
    "sorted_test_video_list = sorted(test_spatial_video_list, key=lambda x: x[\"video_id\"])\n",
    "sorted_test_video_aug33_list = sorted(test_spatial_video_aug33_list, key=lambda x: x[\"video_id\"])\n",
    "sorted_test_video_aug67_list = sorted(test_spatial_video_aug67_list, key=lambda x: x[\"video_id\"])\n",
    "sorted_test_video_aug100_list = sorted(test_spatial_video_aug100_list, key=lambda x: x[\"video_id\"])\n",
    "\n",
    "print(f\"augno list len: {len(sorted_test_video_list)}\")\n",
    "print(f\"aug100 list len: {len(sorted_test_video_aug33_list)}\")\n",
    "print(f\"aug67 list len: {len(sorted_test_video_aug67_list)}\")\n",
    "print(f\"aug33 list len: {len(sorted_test_video_aug100_list)}\")\n",
    "\n",
    "# REPAIR GRAPH\n",
    "def repair_graph(dict_list):\n",
    "    \"\"\"\n",
    "    func: in dict_list, repair faulty graph that only give string rather than dictionalry in the \"init_status\"\n",
    "    input: dict_list\n",
    "    output: dict_list with repaired graphs\n",
    "    \"\"\"\n",
    "    for i in range(len(dict_list)):\n",
    "        graph = dict_list[i]['spatial_data']\n",
    "        id = dict_list[i]['video_id']\n",
    "        for obj in graph:\n",
    "            init_status = obj.get(\"init_status\")\n",
    "            \n",
    "            if isinstance(init_status, str):\n",
    "                obj[\"init_status\"] = {\n",
    "                    \"status\": init_status,\n",
    "                    \"container\": None\n",
    "                }\n",
    "    return dict_list\n",
    "\n",
    "\n",
    "sorted_test_video_list = sorted(test_spatial_video_list, key=lambda x: x[\"video_id\"])\n",
    "sorted_test_video_list= repair_graph(sorted_test_video_list)\n",
    "sorted_test_video_aug33_list = sorted(test_spatial_video_aug33_list, key=lambda x: x[\"video_id\"])\n",
    "sorted_test_video_aug67_list = sorted(test_spatial_video_aug67_list, key=lambda x: x[\"video_id\"])\n",
    "sorted_test_video_aug100_list = sorted(test_spatial_video_aug100_list, key=lambda x: x[\"video_id\"])\n",
    "\n",
    "\n",
    "# for i in range(len(sorted_test_video_list)):\n",
    "#     print(sorted_test_video_list[i]['video_id'])\n",
    "\n",
    "with open(PATH_SOURCE_TARGET_INPUT, \"rb\") as f:\n",
    "    source_target_list = pickle.load(f)\n",
    "    \n",
    "\n",
    "print(f\"source_target_list len: {len(source_target_list)}\")\n",
    "for l in source_target_list:\n",
    "    print(f\"list len in each element: {len(l)}\")\n",
    "\n",
    "print(source_target_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_paths(baseline_output_path:str, testset_length:int):\n",
    "    \"\"\"\n",
    "    func: return file path list for baseline folder\n",
    "    input: baseline output folder absolute path\n",
    "    output: sorted list[file1, file2, ...]\n",
    "    \"\"\"\n",
    "    print(\"aaa\")\n",
    "\n",
    "def load_results(baseline_filepaths:list):\n",
    "    \"\"\" \n",
    "    func: read and organize results of paths in list\n",
    "    input: baseline_filepaths\n",
    "    output: baseline_result_list [[core_activity, source_taxnomy, target_taxnomy, target_sequence, seq_bool, taxo_bool], [], ....]\n",
    "    \"\"\"\n",
    "    baseline_results = []\n",
    "    for i in range(len(baseline_filepaths)):\n",
    "        result = []\n",
    "        core_activty = None\n",
    "        source_taxnomy = None\n",
    "        target_taxonomy = None\n",
    "        target_sequence = None\n",
    "        seq_bool = None\n",
    "        taxo_bool = None\n",
    "\n",
    "        # read files (try)\n",
    "\n",
    "        # fill each value\n",
    "        result.append(core_activty)\n",
    "        result.append(source_taxnomy)\n",
    "        result.append(target_taxonomy)\n",
    "        result.append(target_sequence)\n",
    "        result.append(seq_bool)\n",
    "        result.append(taxo_bool)\n",
    "        baseline_results.append(result)\n",
    "    \n",
    "    return baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12e164",
   "metadata": {},
   "source": [
    "## Read Sequences and Configure into a List\n",
    "- make list of augmentation mode\n",
    "- make list of input sequencs\n",
    "-----------------------------------\n",
    "- make list of core activity\n",
    "- make list of source taxonomy\n",
    "- make list of common taxonomy\n",
    "- make list of target taxonomy\n",
    "- make list of target sequences\n",
    "- make list of seq bool\n",
    "- make list of tax bool\n",
    "-----------------------------------\n",
    "- make list of similarity between scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf074b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. MAKE SOURCE TARGET PAIR CHUNK FOR DIFFERENT AUGMENTATION MODES\n",
    "source_list = [] # [0,0,0,0,1,1,1,1,...,283] -> [0,1,2,3,..71,0,1,2,3,4..71,...71]\n",
    "target_list = [] # [augno_0: 55, aug33_0: 33,aug67_0: 28,aug100_0: 22,...] -> [55,26,22,...]\n",
    "\n",
    "# Since source and target for each augmodes are mixed in element level, need to separate them to different lists.\n",
    "source_list_augno = [row[0] for row in source_target_list]\n",
    "source_list_aug33 = [row[0] for row in source_target_list]\n",
    "source_list_aug67 = [row[0] for row in source_target_list]\n",
    "source_list_aug100 = [row[0] for row in source_target_list]\n",
    "source_list.extend(source_list_augno)\n",
    "source_list.extend(source_list_aug33)\n",
    "source_list.extend(source_list_aug67)\n",
    "source_list.extend(source_list_aug100)\n",
    "\n",
    "target_list_augno = [row[1] for row in source_target_list]\n",
    "target_list_aug33 = [row[2] for row in source_target_list]\n",
    "target_list_aug67 = [row[3] for row in source_target_list]\n",
    "target_list_aug100 = [row[4] for row in source_target_list]\n",
    "target_list.extend(target_list_augno)\n",
    "target_list.extend(target_list_aug33)\n",
    "target_list.extend(target_list_aug67)\n",
    "target_list.extend(target_list_aug100)\n",
    "# print(f\"len sourceidx targetidx {len(source_list)}, {len(target_list)}\")\n",
    "\n",
    "# 1. make list of sequences\n",
    "input_sequence_list = []\n",
    "for i in range(len(source_list)):\n",
    "    source_action_sequence, source_scene_graph = agent_init.get_video_info(source_list[i])\n",
    "    input_sequence_list.append(source_action_sequence)\n",
    "\n",
    "# 2. load files\n",
    "def load_file(path):\n",
    "    try:          \n",
    "         with open(path, \"rb\") as f:\n",
    "             data = pickle.load(f)\n",
    "             return data\n",
    "    except:\n",
    "         return None\n",
    "\n",
    "# For each baselines, save results so that augno->aug33->aug67->aug100 mode chunks are listed sequentially\n",
    "baseline_paths = [PATH_BASELINE_RAG, PATH_BASELINE_NORAG, PATH_BASELINE_1DIRECT, PATH_BASELINE_1GOALMEDIATION]\n",
    "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
    "aug_modes = [\"augno\", \"aug33\", \"aug67\", \"aug100\"]\n",
    "for baseline_idx, baseline_path in enumerate(baseline_paths):  \n",
    "    baseline_results = []\n",
    "    PATH_BASELINE_RESULTS = \"evaluation_result/\" + baselines[baseline_idx] + \".pkl\"\n",
    "    for i in range(len(source_list)):\n",
    "            result_dict = {\"source_idx\":None, \"target_idx\":None,  baseline\": None, \"augmode\": None, \"source_sequence\": None, \"core_activity\": None, \"source_taxnomy\": None, \"common_taxonomy\": None, \"target_taxonomy\": None, \"target_sequence\": None, \"sequence_boolean\": None, \"taxonomy_boolean\": None, \"pairwise_similarity\": None }\n",
    "            \n",
    "            #fill dict without file read\n",
    "            result_dict[\"source_idx\"] = i\n",
    "            result_dict[\"target_idx\"]=target_list[i]\n",
    "            result_dict[\"baseline\"] = baselines[baseline_idx]\n",
    "            aug_idx = len(aug_modes)*i // len(source_list)\n",
    "            result_dict[\"augmode\"] = aug_modes[aug_idx]\n",
    "            result_dict[\"source_sequence\"] = input_sequence_list[i]\n",
    "\n",
    "            #fill dict with external pickle file\n",
    "            common_result_path = baseline_path + f\"/pair{i}_agent\"            \n",
    "            result_dict[\"core_activity\"] = load_file(common_result_path+\"1a.pkl\")            \n",
    "            result_dict[\"source_taxnomy\"] = load_file(common_result_path+\"1b.pkl\")\n",
    "            result_dict[\"common_taxonomy\"] = load_file(common_result_path+\"2a.pkl\")\n",
    "            result_dict[\"target_taxonomy\"] = load_file(common_result_path+\"2b.pkl\")\n",
    "            result_dict[\"target_sequence\"] = load_file(common_result_path+\"3.pkl\")\n",
    "            result_agent4= load_file(common_result_path+\"4.pkl\")\n",
    "            if(result_agent4 == None):\n",
    "                result_dict[\"sequence_boolean\"] = None\n",
    "                result_dict[\"taxonomy_boolean\"] = None       \n",
    "            else:\n",
    "                values = [\n",
    "                    line.split(\":\")[1].strip()\n",
    "                    for line in result_agent4.strip().splitlines()\n",
    "                    if \":\" in line\n",
    "                ]\n",
    "\n",
    "                result_dict[\"sequence_boolean\"] = True if values[0] == 'yes' else False\n",
    "                result_dict[\"taxonomy_boolean\"] = True if values[1] == 'yes' else False\n",
    "\n",
    "        #fill dict with external pairwise scene f1 score\n",
    "        #augmode, source_idx, target_idx, name in data_annotation/spatial_pairsim_result/comparison_+\"modename\"+\"_idx.pkl\"\n",
    "            file_index = i % len(target_list_augno)\n",
    "            target_file_index = target_list[i] % len(target_list_augno)\n",
    "\n",
    "            PATH_PAIRSIM_FILE = PATH_PAIRSIM + f'/comparision_{aug_modes[aug_idx]}_{file_index}.pkl'\n",
    "            print(f\"{file_index}th file for {aug_modes[aug_idx]} mode, target:{target_file_index}\")\n",
    "\n",
    "            with open(PATH_PAIRSIM_FILE, \"rb\") as f:\n",
    "                similarity_data = pickle.load(f)                \n",
    "                entity_result = similarity_data[target_file_index]['entity_result']\n",
    "                f1_score = entity_result[\"f1_score\"]\n",
    "                print(f1_score)\n",
    "                result_dict[\"pairwise_similarity\"] = f1_score\n",
    "\n",
    "        #append dict for each baseline\n",
    "            baseline_results.append(result_dict)\n",
    "    \n",
    "    #3. save baseline results into a single pickle file\n",
    "    if os.path.exists(PATH_BASELINE_RESULTS):\n",
    "        os.remove(PATH_BASELINE_RESULTS)            \n",
    "        print(f\"removed existing file for {PATH_BASELINE_RESULTS}\")\n",
    "\n",
    "    with open(PATH_BASELINE_RESULTS, 'wb') as f:\n",
    "        pickle.dump(baseline_results, f)\n",
    "        print(f\"saved {baselines[baseline_idx]} file at {PATH_BASELINE_RESULTS}\")\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcc30a",
   "metadata": {},
   "source": [
    "## Perform Numerical Calculation of Results\n",
    "\n",
    "### base results\n",
    "- pairwise scene similarity\n",
    "- seq2seq similarity\n",
    "- seq2seq taxonomy similarity\n",
    "### plot\n",
    "- per scenario similarity analysis\n",
    "- per augmentation, per scenario similarity analysis\n",
    "- per scenario similarity vs similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline paths\n",
    "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
    "aug_modes = [\"augno\", \"aug33\", \"aug67\", \"aug100\"]\n",
    "baseline_results_paths = []\n",
    "for idx in range(len(baselines)):\n",
    "    path = \"evaluation_result/\" + baselines[idx] + \".pkl\"\n",
    "    baseline_results_paths.append(path)\n",
    "print(baseline_results_paths)\n",
    "\n",
    "# load baselines\n",
    "baseline_rag = []\n",
    "baseline_norag = []\n",
    "baseline_1direct = []\n",
    "baseline_1goalmediation = []\n",
    "with open(baseline_results_paths[0], \"rb\") as f:\n",
    "    baseline_rag = pickle.load(f)\n",
    "with open(baseline_results_paths[1], \"rb\") as f:\n",
    "    baseline_norag = pickle.load(f)\n",
    "with open(baseline_results_paths[2], \"rb\") as f:\n",
    "    baseline_1direct = pickle.load(f)\n",
    "with open(baseline_results_paths[3], \"rb\") as f:\n",
    "    baseline_1goalmediation = pickle.load(f)            \n",
    "print(f\"baseline data length {len(baseline_rag)}, {len(baseline_norag)}, {len(baseline_1direct)}, {len(baseline_1goalmediation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for evaluation\n",
    "def calculate_evaluation(baseline_result, path, model):\n",
    "    \"\"\"\n",
    "    func: calculate (similarities) for baseline result items\n",
    "    input: result for one baseline [{dict3}{dict2}..{dictN}]\n",
    "    result: \n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    for idx, dict in enumerate(baseline_result):\n",
    "        evaluation_dict = {\"source_idx\":None, \"target_idx\":None, \"pairwise_similarity\":None,\"sequence_similarity\":None, \"taxonomy_similarity\":None, \"sequence_boolean\":False, \"taxonomy_boolean\": False}\n",
    "        print(f\"{idx}th result\")\n",
    "        sequence_similarity, taxonomy_similarity = compute_similarities(dict, model)\n",
    "        print(f\"{sequence_similarity} {taxonomy_similarity}\")\n",
    "        evaluation_dict[\"source_idx\"]= dict['source_idx']\n",
    "        evaluation_dict[\"target_idx\"]= dict['target_idx']\n",
    "        evaluation_dict[\"pairwise_similarity\"]= dict['pairwise_similarity']\n",
    "        evaluation_dict[\"sequence_similarity\"]= sequence_similarity\n",
    "        evaluation_dict[\"taxonomy_similarity\"]= taxonomy_similarity\n",
    "        evaluation_dict[\"sequence_boolean\"]= dict['sequence_boolean']\n",
    "        evaluation_dict[\"taxonomy_boolean\"]= dict['taxonomy_boolean']\n",
    "        dict_list.append(evaluation_dict)\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "        print(f\"saved baseline evaluation as dataframe\")    \n",
    "    return df    \n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    if norm(vec1) == 0 or norm(vec2) == 0:\n",
    "        return 0.0\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "def safe_parse_sequence(seq):\n",
    "    if seq is None:\n",
    "        return []\n",
    "    if isinstance(seq, list):\n",
    "        return seq\n",
    "    try:\n",
    "        return ast.literal_eval(seq)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "def safe_parse_taxonomy(tax):\n",
    "    if tax is None:\n",
    "        return {}\n",
    "    if isinstance(tax, dict):\n",
    "        return tax\n",
    "    try:\n",
    "        return json.loads(tax)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return {}\n",
    "\n",
    "def compute_similarities(entry, embed_model):\n",
    "    # --- Parse sequences ---\n",
    "    source_seq = safe_parse_sequence(entry.get('source_sequence'))\n",
    "    target_seq = safe_parse_sequence(entry.get('target_sequence'))\n",
    "\n",
    "    if not source_seq or not target_seq:\n",
    "        seq_similarity = 0.0\n",
    "    else:\n",
    "        source_seq_str = ' '.join(source_seq)\n",
    "        target_seq_str = ' '.join(target_seq)\n",
    "        source_seq_emb = embed_model.encode(source_seq_str)\n",
    "        target_seq_emb = embed_model.encode(target_seq_str)\n",
    "        seq_similarity = cosine_similarity(source_seq_emb, target_seq_emb)\n",
    "\n",
    "    # --- Parse taxonomies ---\n",
    "    source_tax = safe_parse_taxonomy(entry.get('source_taxnomy'))\n",
    "    target_tax = safe_parse_taxonomy(entry.get('target_taxonomy'))\n",
    "\n",
    "    if not source_tax or not target_tax:\n",
    "        tax_similarity = 0.0\n",
    "    else:\n",
    "        source_tax_str = ' '.join(f\"{k}: {v}\" for k, v in source_tax.items())\n",
    "        target_tax_str = ' '.join(f\"{k}: {v}\" for k, v in target_tax.items())\n",
    "        source_tax_emb = embed_model.encode(source_tax_str)\n",
    "        target_tax_emb = embed_model.encode(target_tax_str)\n",
    "        tax_similarity = cosine_similarity(source_tax_emb, target_tax_emb)\n",
    "\n",
    "    return seq_similarity, tax_similarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute\n",
    "baselines = [\"rag\",\"norag\",\"1direct\",\"1goalmediation\"]\n",
    "baseline_df_paths = []\n",
    "for idx in range(len(baselines)):\n",
    "    path = \"evaluation_result/\" + baselines[idx] + \"_df\" +\".pkl\"\n",
    "    baseline_df_paths.append(path)\n",
    "\n",
    "\n",
    "print(baseline_df_paths)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "df_rag = calculate_evaluation(baseline_rag, baseline_df_paths[0], model)\n",
    "df_norag = calculate_evaluation(baseline_norag, baseline_df_paths[1], model)\n",
    "df_1direct = calculate_evaluation(baseline_1direct, baseline_df_paths[2], model)\n",
    "df_1goalmediation = calculate_evaluation(baseline_1goalmediation, baseline_df_paths[3], model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation functions\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "\n",
    "# Step 1: Filter where taxonomy_boolean is True\n",
    "def plot_taxonomy(df):\n",
    "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
    "    # filtered_df = df\n",
    "\n",
    "    # Step 2: Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['pairwise_similarity'], filtered_df['taxonomy_similarity'], alpha=0.7)\n",
    "    plt.xlabel('Pairwise Similarity')\n",
    "    plt.ylabel('Taxonomy Similarity')\n",
    "    plt.title('Pairwise vs. Taxonomy Similarity (Only where taxonomy_boolean=True)')\n",
    "\n",
    "    plt.xlim(0, 0.3)\n",
    "    plt.ylim(-1, 1)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sequence(df):\n",
    "    filtered_df = df[df['taxonomy_boolean'] == True]\n",
    "    filtered_df = filtered_df[filtered_df['sequence_boolean'] == True]\n",
    "\n",
    "    # filtered_df = df\n",
    "\n",
    "    # Step 2: Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['pairwise_similarity'], filtered_df['sequence_similarity'], alpha=0.7)\n",
    "    plt.xlabel('Pairwise Similarity')\n",
    "    plt.ylabel('Sequence Similarity')\n",
    "    plt.title('Pairwise vs. Sequence Similarity (Only where sequence_boolean=True)')\n",
    "\n",
    "    plt.xlim(0, 0.3)\n",
    "    plt.ylim(-0.3, 0.3)  \n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "plot_taxonomy(df_rag)\n",
    "plot_taxonomy(df_norag)\n",
    "plot_taxonomy(df_1direct)\n",
    "plot_taxonomy(df_1goalmediation)\n",
    "\n",
    "plot_sequence(df_rag)\n",
    "plot_sequence(df_norag)\n",
    "plot_sequence(df_1direct)\n",
    "plot_sequence(df_1goalmediation)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
